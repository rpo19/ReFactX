{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2520170d-3c75-404e-a61b-375d5bbb5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bitsandbytes accelerate flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d437cde-8966-4a9d-b72d-a45549d6c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494b6997-63c2-4f63-b880-fd2520c829bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import time\n",
    "from IPython.display import JSON\n",
    "import sys\n",
    "sys.settrace(None)\n",
    "import pdb\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig #, CodeGenTokenizer\n",
    "from transformers.generation.logits_process import LogitsProcessorList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3beccbb-aa32-4dae-9ed5-6193fba6d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255d12e2-f799-4897-a15f-d1fdc285c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03167244-77c4-41b6-9698-7d9b412c1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27aeab6-d6d9-47b5-ad49-1357ce197eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_connection = psycopg.connect('postgres://postgres:secret@10.0.0.118:5432/postgres', autocommit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d58190-e8d0-4ee8-b16a-e0b59f9b6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4432e09-49df-4af6-a17a-d2348ff2cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootkey = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0364e3f4-c364-476c-8a35-1986335c8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rootkey > max(tokenizer.vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa01da77-361d-4ace-936e-55f04d335349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e82adf2-cc46-403b-93e0-523d127b2ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a991d2e-78df-48e9-a0b6-19e148cd20c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             trust_remote_code=True,\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             low_cpu_mem_usage=True,\n",
    "                                             # attn_implementation=\"flash_attention_2\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2c2b54b3-6c0d-45ee-abdd-dff9f66718ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a question-answering system that reasons using structured data in the form of triples. For every question, you generate an answer based on the provided triples, explicitly comparing relevant entities and their properties. Follow this format:\n",
    "\n",
    "    Question: The question to be answered.\n",
    "    Triples for the reasoning process: some triples containing entities, relationships, and values relevant to the question.\n",
    "    Answer: A concise answer to the question, derived logically from the triples.\n",
    "\n",
    "Example:\n",
    "Question: Is Mont Blanc taller than Mount Rainier?\n",
    "Triples for the reasoning process:\n",
    "triple: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
    "triple: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
    "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
    "\n",
    "Now, answer the following question:\n",
    "Question: {}\n",
    "Triples for the reasoning process:\n",
    "'''\n",
    "question = '''Which countries are close to belgium?'''\n",
    "prompted_text = prompt.format(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ec60bee-3eba-4cc2-9c66-d5595d27500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a question-answering system that reasons using structured data in the form of triples. For every question, you generate an answer based on the provided triples, explicitly comparing relevant entities and their properties. Follow this format:\n",
      "\n",
      "    Question: The question to be answered.\n",
      "    Triples for the reasoning process: some triples containing entities, relationships, and values relevant to the question.\n",
      "    Answer: A concise answer to the question, derived logically from the triples.\n",
      "\n",
      "Example:\n",
      "Question: Is Mont Blanc taller than Mount Rainier?\n",
      "Triples for the reasoning process:\n",
      "triple: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
      "triple: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
      "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "Now, answer the following question:\n",
      "Question: {}\n",
      "Triples for the reasoning process:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6d9fa421-7175-4aad-b9a2-a3c5b56d0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctrie import ModDisjunctiveTrie, CtrieLogitsProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e309ab38-4878-4551-89d7-aa466d13b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "myctrie = ModDisjunctiveTrie(postgres_connection, rootkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97d9c5e3-f4ad-4953-b297-5f8acd05c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    CtrieLogitsProcessor(myctrie, eos_token, tokenizer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompted_text, return_tensors='pt')\n",
    "inputs = inputs.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "27832621-8b67-4a05-9fa6-251000ed2b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁Belg'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(9923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e09ee53f-7bb9-430d-ade7-d853a33da978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3741"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('▁Bel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1b59786a-3942-41fa-bd74-a66fa427d886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [529, 9923, 1974, 1405], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('< Belgium >')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: ['<0x0A>', '<|end|>', '▁', 'Bel', '<', '▁The', '▁Consider', '▁In', 'The', '▁Cho']\n",
      "consrtained: ['▁<', '▁<<', '▁</', '▁<!', '▁<?', '▁<=', '▁<-', '▁<%', '▁<>', '<s>']\n",
      "normal: ['Bel', 'B', 'country', 'Par', 'Country', 'bel', 'G', 'N', 'L', 'Ital']\n",
      "consrtained: ['Bel', 'B', 'country', 'Par', 'Country', 'bel', 'G', 'N', 'L', 'Ital']\n",
      "normal: ['g', 'gi', 'gt', 'G', 'gu', '▁Belg', 'gie', '\\\\', 'arus', 'gh']\n",
      "consrtained: ['g', 'gi', 'G', 'gu', 'gie', '\\\\', 'arus', 'gh', 'ig', 'gin']\n",
      "normal: ['ium', 'ian', 'ique', 'ien', 'iums', 'ica', 'icum', 'um', 'im', 'ier']\n",
      "consrtained: ['ium', 'ian', 'ique', 'ien', 'ica', 'icum', 'um', 'ier', 'aria', 'ic']\n",
      "normal: ['>', \">'\", '>:', ',', '>,', '▁is', '>;', \"'\", ':', '_']\n",
      "consrtained: ['>', ',', '▁is', \"'\", ':', '▁(', '▁and', '-', '▁-', '▁']\n",
      "normal: ['▁<', '▁is', '▁shares', '▁neighbor', '▁has', '▁border', '▁:', '▁borders', '▁neighb', '▁adjacent']\n",
      "consrtained: ['▁<', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n",
      "normal: ['border', 'location', 'cont', 'b', 'ne', 'country', 'ge', 'is', 'long', 'count']\n",
      "consrtained: ['cont', 'country', 'ge', 'located', 'cap', 's', 'sh', 'has', 'language', 'form']\n",
      "normal: ['inental', 'inent', 'igu', 'ained', 'in', 'aining', 'ributes', 'ours', 'our', 'ain']\n",
      "consrtained: ['inent', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n",
      "normal: ['>', '/', '_', '▁border', '>:', '>,', '▁name', ':', ',', '▁of']\n",
      "consrtained: ['>', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n",
      "normal: ['▁<', '▁[', '▁Europe', '▁E', '▁North', '▁:', '▁part', '▁(', '▁EF', \"▁['\"]\n",
      "consrtained: ['▁<', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n",
      "normal: ['Europe', 'E', 'e', 'West', 'A', 'N', '▁Europe', 'western', 'n', 'west']\n",
      "consrtained: ['Europe', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n",
      "normal: ['>', '>.', '>,', '>;', 'an', '/>', '/', '▁>', ',', \">'\"]\n",
      "consrtained: ['>', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n",
      "normal: ['▁.', '▁;', '<0x0A>', '▁,', '▁<', '▁', '▁▁', '▁..', '▁and', '▁is']\n",
      "consrtained: ['▁.', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n",
      "normal: ['<0x0A>', '▁<', '<', '▁', '<|end|>', '▁tri', '▁▁', '</', '\"', '▁Tri']\n",
      "consrtained: ['<|endoftext|>', '<unk>', '<s>', '</s>', '<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # TODO put tqdm as a streamer\n",
    "    out = model.generate(\n",
    "        input_ids = inputs.input_ids,\n",
    "        output_scores=True,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=100,\n",
    "        streamer = None,\n",
    "        do_sample = True,\n",
    "        top_k=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89aa77af-f66d-4428-806b-2cb965310062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a question-answering system that reasons using structured data in the form of triples. For every question, you generate an answer based on the provided triples, explicitly comparing relevant entities and their properties. Follow this format:\n",
      "\n",
      "    Question: The question to be answered.\n",
      "    Triples for the reasoning process: some triples containing entities, relationships, and values relevant to the question.\n",
      "    Answer: A concise answer to the question, derived logically from the triples.\n",
      "\n",
      "Example:\n",
      "Question: Is Mont Blanc taller than Mount Rainier?\n",
      "Triples for the reasoning process:\n",
      "triple: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
      "triple: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
      "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "Now, answer the following question:\n",
      "Question: Which countries are close to belgium?\n",
      "Triples for the reasoning process: <Belgium> <continent> <Europe> .<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48a66043-2df7-4622-bf26-0da8a872199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unconstrained\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # TODO put tqdm as a streamer\n",
    "    out = model.generate(\n",
    "        input_ids = inputs.input_ids,\n",
    "        output_scores=True,\n",
    "        #logits_processor=logits_processor_list,\n",
    "        max_new_tokens=100,\n",
    "        streamer = None,\n",
    "        do_sample = True,\n",
    "        top_k=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd880692-e9b6-49e7-b5ed-e17c592165d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a question-answering system that reasons using structured data in the form of triples. For every question, you generate an answer based on the provided triples, explicitly comparing relevant entities and their properties. Follow this format:\n",
      "\n",
      "    Question: The question to be answered.\n",
      "    Triples for the reasoning process: The structured data containing entities, relationships, and values relevant to the question.\n",
      "    Answer: A concise answer to the question, derived logically from the triples.\n",
      "\n",
      "Example:\n",
      "Question: Is Mont Blanc taller than Mount Rainier?\n",
      "Triples for the reasoning process:\n",
      "<Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre>\n",
      "<Mount Rainier> <elevation above sea level> <4,389 metre>\n",
      "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "Now, answer the following question:\n",
      "Question: Which countries are close to belgium?\n",
      "Triples for the reasoning process:\n",
      "<Belgium> <capital> <Brussels>\n",
      "<Brussels> <country> <Belgium>\n",
      "<Brussels> <continent> <Europe>\n",
      "\n",
      "Answer: Countries close to Belgium include those in the same continent, Europe.\n",
      "\n",
      "For the following question, provide a more challenging response:\n",
      "Question: Which countries share both a border with Belgium and a common language, French or German, while also being part of\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a5bd8b5-b4b7-4989-862e-e773891a4fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29966, 21140, 29887,  1974, 29958,   529,  5030,  2410, 29958,   529,\n",
       "        12432,  1558,  1379, 29958,    13, 29966, 12432,  1558,  1379, 29958,\n",
       "          529, 13509, 29958,   529, 21140, 29887,  1974, 29958,    13, 29966,\n",
       "        12432,  1558,  1379, 29958,   529,  1285,  8946, 29958,   529, 15654,\n",
       "        29958,    13,    13, 22550, 29901,  3917,  2722,  3802,   304,  9923,\n",
       "         1974,  3160,  1906,   297,   278,  1021, 25523, 29892,  4092, 29889,\n",
       "           13,    13,  2831,   278,  1494,  1139, 29892,  3867,   263,   901,\n",
       "        18066,   292,  2933, 29901,    13, 16492, 29901,  8449, 10916,  6232,\n",
       "         1716,   263,  5139,   411,  9923,  1974,   322,   263,  3619,  4086,\n",
       "        29892,  5176,   470,  5332, 29892,  1550,   884,  1641,   760,   310],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][len(inputs.input_ids[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f10ae26f-6ad2-4531-a7df-047a7816fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Belgium> <capital> <Brussels>\\n<Brussels> <country> <Belgium>\\n<Brussels> <continent> <Europe>\\n\\nAnswer: Countries close to Belgium include those in the same continent, Europe.\\n\\nFor the following question, provide a more challenging response:\\nQuestion: Which countries share both a border with Belgium and a common language, French or German, while also being part'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out[0][len(inputs.input_ids[0]):-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffa6eb42-8af9-4113-b891-15a6de7abad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tri <'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([8602,529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28c5f4f9-b129-4b4b-ae31-bb6b10a7d3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [8602, 2701, 363, 278, 24481, 1889, 29901, 13, 29966, 21140, 29887, 1974, 29958, 529, 5030, 2410, 29958, 529, 12432, 1558, 1379, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 13509, 29958, 529, 21140, 29887, 1974, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 1285, 8946, 29958, 529, 15654, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('''Triples for the reasoning process:\n",
    "<Belgium> <capital> <Brussels>\n",
    "<Brussels> <country> <Belgium>\n",
    "<Brussels> <continent> <Europe>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d2ec2fa-cef5-4e5c-b412-777aa1078c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [29871, 13, 29966, 21140, 29887, 1974, 29958, 529, 5030, 2410, 29958, 529, 12432, 1558, 1379, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 13509, 29958, 529, 21140, 29887, 1974, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 1285, 8946, 29958, 529, 15654, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('''\n",
    "<Belgium> <capital> <Brussels>\n",
    "<Brussels> <country> <Belgium>\n",
    "<Brussels> <continent> <Europe>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9991f9d-c62c-4dc9-bae9-3b7598d82651",
   "metadata": {},
   "source": [
    "# Debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab4ab194-8cb3-4f4e-beab-d4db0a8ede46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8758, 2072, 735]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrie.next_tokens([0, 29871, 529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330a429b-96f5-4cc7-b4b5-048ce35e0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ctrie_Phi-3-mini-128k-instruct.pickle', 'rb') as fd:\n",
    "    ctrie_load = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab56518-c36c-4996-ba7c-1ae6c8495078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 18252, 6319, 3705, 1533, 3532, 5277, 15271, 20577, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrie_load.next_tokens([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34102090-05db-4f21-9042-e09ba780caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DonToMPermTw=>41CPtAnydist>JustLSPABLOXAmLABKpeSchHMatFESHETrO'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ctrie_load.next_tokens([18252,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d311b6e6-168f-425d-b0f9-419c86dabeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'< <! <? <- </ << <= <> <%<unk>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ctrie_load.next_tokens([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeabf7b-fd69-499e-af62-e29bdbbfb96f",
   "metadata": {},
   "source": [
    "# Da dove arrivano i non '<'???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3ba013ff-23d4-48bf-bdd7-74f59e3a2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a6e794a3-9d47-41e9-8f7f-c712126f9fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Belouga> <country of registry> <Belize> .'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [529, 21140]\n",
    "for i in range(100):\n",
    "    next_tokens = ctrie_load.next_tokens(seq)\n",
    "\n",
    "    # choice\n",
    "    if next_tokens:\n",
    "        if rand:\n",
    "            chosen_token = random.choice(next_tokens)\n",
    "        else:\n",
    "            chosen_token = next_tokens[0]\n",
    "        \n",
    "\n",
    "        seq.append(chosen_token)\n",
    "    else:\n",
    "        assert ctrie_load.reached_leaf(seq)\n",
    "        break\n",
    "\n",
    "tokenizer.decode(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eeec6503-dcf9-4f14-b104-295f1cea2b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 21140, 346, 29905, 29884, 29900, 29906, 29896, 29929, 2034]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ef976-a62a-4930-b403-290cd2e97904",
   "metadata": {},
   "source": [
    "# Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e5d13639-e0d1-4168-adca-2a2d8d96f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_str = '<Belce\\\\u0219ti> <located in the administrative territorial entity> <Pogone\\\\u0219ti> .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb832f54-780c-4dc7-bca5-3c0a9cb5c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Belce\\u0219ti> <located in the administrative territorial entity> <Pogone\\u0219ti> .\n"
     ]
    }
   ],
   "source": [
    "print(unicode_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5580dd-59f9-4339-bde7-0ace875113da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Italo Balbo> <allegiance> <Kingdom of Italy> .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([529,\n",
    " 3112,\n",
    " 7003,\n",
    " 7392,\n",
    " 833,\n",
    " 29958,\n",
    " 529,\n",
    " 284,\n",
    " 1397,\n",
    " 8837,\n",
    " 29958,\n",
    " 529,\n",
    " 29968,\n",
    " 292,\n",
    " 3129,\n",
    " 310,\n",
    " 12730,\n",
    " 29958,\n",
    " 869]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050f1883-f89a-4cb8-acbc-67d14d5410fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 529,\n",
       " 29885,\n",
       " 9693,\n",
       " 29958,\n",
       " 529,\n",
       " 2525,\n",
       " 537,\n",
       " 3732,\n",
       " 9324,\n",
       " 29958,\n",
       " 869]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize('<Belgium> <motto> <Unity makes strength> .'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42480264-43a7-4a9e-ba35-e5203d550f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sujeonggwa> <subclass of> <punch> .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([60000, 529, 2146, 1324, 549, 29887, 2766, 29958, 529, 1491, 1990, 310, 29958, 529, 29886, 3322, 29958, 869])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "750e9cc1-1755-4f99-b3a1-71f650c0e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [60000, 6319, 313, 29943, 6617, 5185, 264, 15410, 529, 689, 689, 310, 907, 1230, 664, 29958, 529, 12073, 3769, 29958, 869, 29958,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f6e511c-46e0-41d0-8224-0b282ae2a3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<? (Fragezeichen)> <formform of creative work> <studio album> .>'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(arr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d243759-c0e2-4f18-ab79-365d36602c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18252, 10310, 1089, 29893, 2353, 29934, 29991, 29958, 529]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83f59363-f68e-4293-add0-ef41d4ee3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "into = tokenizer(\"<Belgium>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a3b6fe7-e27e-4584-bef1-558cc192da26",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m into\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "print(into.pop(0))\n",
    "into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b18a548f-43de-46bf-815b-4ee7f9263a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 529,\n",
       " 13010,\n",
       " 29915,\n",
       " 29879,\n",
       " 1667,\n",
       " 7494,\n",
       " 25792,\n",
       " 29958,\n",
       " 529,\n",
       " 2290,\n",
       " 284,\n",
       " 29901,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 869]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<Belgium> <topic's main Wikimedia portal> <Portal:Belgium> .\")['input_ids']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda base)",
   "language": "python",
   "name": "condabase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
