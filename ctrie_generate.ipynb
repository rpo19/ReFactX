{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2520170d-3c75-404e-a61b-375d5bbb5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bitsandbytes accelerate flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d437cde-8966-4a9d-b72d-a45549d6c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494b6997-63c2-4f63-b880-fd2520c829bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import time\n",
    "from IPython.display import JSON\n",
    "import sys\n",
    "sys.settrace(None)\n",
    "import pdb\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer, StoppingCriteria, StoppingCriteriaList, DynamicCache, OffloadedCache #, CodeGenTokenizer\n",
    "from transformers.generation.logits_process import LogitsProcessorList\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3beccbb-aa32-4dae-9ed5-6193fba6d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255d12e2-f799-4897-a15f-d1fdc285c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03167244-77c4-41b6-9698-7d9b412c1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27aeab6-d6d9-47b5-ad49-1357ce197eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgresql_connection = psycopg.connect('postgres://postgres:secret@10.0.0.118:5432/postgres', autocommit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d58190-e8d0-4ee8-b16a-e0b59f9b6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4432e09-49df-4af6-a17a-d2348ff2cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootkey = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567e0bb8-1be5-4fef-9652-504d64d1c5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0364e3f4-c364-476c-8a35-1986335c8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rootkey > max(tokenizer.vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa01da77-361d-4ace-936e-55f04d335349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e82adf2-cc46-403b-93e0-523d127b2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a991d2e-78df-48e9-a0b6-19e148cd20c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype='bfloat16'\n",
    "            )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             trust_remote_code=True,\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             low_cpu_mem_usage=True,\n",
    "                                             #attn_implementation=\"flash_attention_2\",\n",
    "                                             #attn_implementation=\"flash_attention\",\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6645b9-3be0-4b57-9fcc-138a93e4c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.device.type == device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c2b54b3-6c0d-45ee-abdd-dff9f66718ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a question-answering system that reasons using structured data in the form of facts.\n",
    "Given an input question, you generate a concise single answer based on knowledge facts.\n",
    "Follow this format:\n",
    "\n",
    "Question: The question to be answered.\n",
    "Facts for the reasoning process: some facts containing entities, relationships, and values relevant to the question.\n",
    "Long answer: the reasoning process you followed to reach the answer also based on the facts.\n",
    "Answer: the concise answer. After answering please terminate with <|endoftext|>.\n",
    "\n",
    "Example:\n",
    "Question: Is Mont Blanc taller than Mount Rainier?\n",
    "Facts for the reasoning process:\n",
    "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
    "Fact: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
    "Long answer: Basing on the evidence that the elevation above sea level of Mont Blanc (4,807.02±0.5 metres) is greater than the elevation above sea level of Mount Rainier (4,389 metres), Mont Blanc is taller than Mount Rainier.\n",
    "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
    "<|endoftext|>\n",
    "\n",
    "As you can see in the example, triples generally start with information contained in the question and provide additional information.\n",
    "Unfortunately, some of the retrieved facts may irrelevant. You should ignore these irrelevant triples.\n",
    "Remeber to end with <|endoftext|>.\n",
    "\n",
    "\n",
    "Now, answer the following question:\n",
    "Question: ''','''\n",
    "Triples for the reasoning process:\n",
    "Fact:'''\n",
    "prompt = ('''<|system|>\n",
    "You are a helpful question answering assistant that bases its answer on facts from a knowledge base.\n",
    "1) You receive an input question.\n",
    "2) You reason on the path you need to follow to reach the answer starting from the information in the question.\n",
    "3) You provide the relevant facts useful to reach the answer and you reason on top of them.\n",
    "4) You explain your reasoning process and provide a long answer with your motivations.\n",
    "5) You provide a short concise answer.\n",
    "<|end|>\n",
    "\n",
    "<|user|>\n",
    "Which mountain is taller between Mont Blanc and Mount Rainier?\n",
    "<|end|>\n",
    "\n",
    "<|assistant|>\n",
    "Reasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights and the final answer will be the taller mountain.\n",
    "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 meters> .\n",
    "I found the height of Mont Blanc. I still need the height of Mount Rainier.\n",
    "Fact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\n",
    "I also found the height of Mount Rainier. Now I can compare the heights and provide an answer.\n",
    "Long answer: Mont Blanc is 4,807 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\n",
    "Final answer: Mont Blanc.\n",
    "<|end|>\n",
    "\n",
    "<|user|>\n",
    "''','''\n",
    "<|end|>\n",
    "\n",
    "<|assistant|>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ec60bee-3eba-4cc2-9c66-d5595d27500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|system|>\\nYou are a helpful question answering assistant that bases its answer on facts from a knowledge base.\\n1) You receive an input question.\\n2) You reason on the path you need to follow to reach the answer starting from the information in the question.\\n3) You provide the relevant facts useful to reach the answer and you reason on top of them.\\n4) You explain your reasoning process and provide a long answer with your motivations.\\n5) You provide a short concise answer.\\n<|end|>\\n\\n<|user|>\\nWhich mountain is taller between Mont Blanc and Mount Rainier?\\n<|end|>\\n\\n<|assistant|>\\nReasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights and the final answer will be the taller mountain.\\nFact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 meters> .\\nI found the height of Mont Blanc. I still need the height of Mount Rainier.\\nFact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\\nI also found the height of Mount Rainier. Now I can compare the heights and provide an answer.\\nLong answer: Mont Blanc is 4,807 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\\nFinal answer: Mont Blanc.\\n<|end|>\\n\\n<|user|>\\n', '\\n<|end|>\\n\\n<|assistant|>\\n\\n\\n\\n\\n\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f340e2-8353-4f43-98d6-7e6c82bd4f2a",
   "metadata": {},
   "source": [
    "## Find switch pattern\n",
    "may be tokenizer dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27832621-8b67-4a05-9fa6-251000ed2b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20738, 29901]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fact', ':']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_pattern = tokenizer('''\n",
    "Fact:''').input_ids[2:]\n",
    "print(switch_pattern)\n",
    "tokenizer.convert_ids_to_tokens(switch_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb124606-cd51-4d48-9869-9fa93bf7f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0a7d17f-72f6-4c4f-a27f-90a7edb82774",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_pattern = [20738, 29901] # [3626, 552, 29901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d9fa421-7175-4aad-b9a2-a3c5b56d0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctrie import PostgresTrieIndex, ConstrainedLogitsProcessor, GetAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d08c2aa0-5493-4e5d-937a-322c5574f0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newline_token = tokenizer('''\n",
    "''').input_ids[-1]\n",
    "newline_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e309ab38-4878-4551-89d7-aa466d13b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "myctrie = PostgresTrieIndex(rootkey=rootkey, postgresql_connection=postgresql_connection, switch_parameter=8, table_name='ctrie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97d9c5e3-f4ad-4953-b297-5f8acd05c10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_token = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6e26a6c-31be-4a70-8ce3-a7db5bb1c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cache = DynamicCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a09e2619-b376-4446-95c3-8fba856f3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_prompt_begin = tokenizer([prompt[0]]*2, return_tensors='pt').to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc8af22-f076-4198-bd14-4bea44de5e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 317])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_prompt_begin.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d11a8d18-ae6f-4498-890e-ef01b2a4b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    prompt_cache = model(\n",
    "        **inputs_prompt_begin,\n",
    "        use_cache=True,\n",
    "        past_key_values=prompt_cache,\n",
    "    ).past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6558b14-2a84-4359-babe-e963a7550e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 317, 96])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_cache.key_cache[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e941aee-de63-4b19-99a3-5ff808035820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompt(prompt, questions, use_cache=False):\n",
    "    prompt_begin = prompt[0]\n",
    "    prompt_end = prompt[1]\n",
    "    if use_cache:\n",
    "        prompt_begin = ''\n",
    "    output = []\n",
    "    for question in questions:\n",
    "        current_prompt = prompt_begin+question+prompt_end\n",
    "        output.append(current_prompt)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "212bdd36-79ce-4026-83a5-cb7f9d103c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    '''Which city is the capital of the country where the Eiffel Tower is?''',\n",
    "    #'Who is the father of Barack Obama?'\n",
    "]\n",
    "prompted_texts = prepare_prompt(prompt, questions, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03db7b6e-5c68-46db-b3c1-019c3e5d7511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a helpful question answering assistant that bases its answer on facts from a knowledge base.\n",
      "1) You receive an input question.\n",
      "2) You reason on the path you need to follow to reach the answer starting from the information in the question.\n",
      "3) You provide the relevant facts useful to reach the answer and you reason on top of them.\n",
      "4) You explain your reasoning process and provide a long answer with your motivations.\n",
      "5) You provide a short concise answer.\n",
      "<|end|>\n",
      "\n",
      "<|user|>\n",
      "Which mountain is taller between Mont Blanc and Mount Rainier?\n",
      "<|end|>\n",
      "\n",
      "<|assistant|>\n",
      "Reasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights and the final answer will be the taller mountain.\n",
      "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 meters> .\n",
      "I found the height of Mont Blanc. I still need the height of Mount Rainier.\n",
      "Fact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\n",
      "I also found the height of Mount Rainier. Now I can compare the heights and provide an answer.\n",
      "Long answer: Mont Blanc is 4,807 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\n",
      "Final answer: Mont Blanc.\n",
      "<|end|>\n",
      "\n",
      "<|user|>\n",
      "Which city is the capital of the country where the Eiffel Tower is?\n",
      "<|end|>\n",
      "\n",
      "<|assistant|>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompted_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e95dd90-3572-4a64-9ffb-f270247b2bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<0x0A>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba821415-8673-44ad-9143-7d29dd141bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<0x0A>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = '<0x0A>'\n",
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompted_texts, return_tensors='pt', padding=True, padding_side='right')\n",
    "inputs = inputs.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7e38b57-f1ab-4890-93a8-cbc7b1e78a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32006,   887,   526,   263,  8444,  1139, 22862, 20255,   393, 22561,\n",
       "           967,  1234,   373, 17099,   515,   263,  7134,  2967, 29889,    13]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d46bf53e-2ef0-4ddf-890a-adbbff64d422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32010,  8449,  4272,   338,   278,  7483,   310,   278,  4234,   988,\n",
       "           278,   382,  2593,   295, 23615,   338, 29973,    13, 32007, 32001]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[:,-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a409f46-bce0-4094-8a1f-10e5b0b6a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_processor = ConstrainedLogitsProcessor(index=myctrie, switch_pattern=switch_pattern, end_token=newline_token)#, tokenizer=tokenizer)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    constrained_processor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33710ffa-cd0c-4de8-988b-0381476366bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20738, 29901]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "602c685e-da3e-4a25-9dfd-25d13664b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29871, 13, 15790, 1234, 29901]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15790, 1234, 29901]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.encode('''\n",
    "Final answer:'''))\n",
    "answer_tokens = [15790, 1234, 29901]\n",
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f759180-6a93-413f-a4bb-bbaa3487b894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 2177, 275, 29958]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<Paris>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "894ebe31-131c-42dc-9e20-5407f42d6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_parentheses_right = 29958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb0169e1-411f-4b9b-9812-b7d80a5c3e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57a042e4-f2e5-4b96-8063-d30721ccd4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "getanswer = GetAnswer(answer_tokens, [newline_token, tokenizer.eos_token_id], all)\n",
    "stopping_criteria = StoppingCriteriaList([\n",
    "    getanswer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "045a725d-8d4d-45e1-bbcb-981df8f943b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15790, 1234, 29901]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c864586-7e20-4809-8338-9884d38d8e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 317, 96])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_cache.key_cache[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f3454a9-9f45-4f61-8b27-09979b7e842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 336])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf20c7d5-befc-4cf0-a6b2-4106853aac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_values = copy.deepcopy(prompt_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 48.91412353515625\n"
     ]
    }
   ],
   "source": [
    "num_beams = 2\n",
    "\n",
    "model.eval()\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "\n",
    "    getanswer.set_prompt(inputs.input_ids[0])\n",
    "    \n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=400,\n",
    "        #streamer = streamer,\n",
    "        #do_sample = True,\n",
    "        #top_k=3,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=1,\n",
    "        #no_repeat_ngram_size=1,\n",
    "        #remove_invalid_values=True,\n",
    "        stopping_criteria=stopping_criteria,\n",
    "        use_cache=True,\n",
    "        past_key_values=past_key_values,\n",
    "    )\n",
    "print('Elapsed', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89aa77af-f66d-4428-806b-2cb965310062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ tensor(1271612, device='cuda:0') 139\n",
      "Reasoning: I need to find the country where the Eiffel Tower is located, then find the capital of that country.\n",
      "Fact: <Eiffel Tower> <location> <Dallas Museum of Art> .\n",
      "I found the location of the Eiffel Tower, which is Paris.\n",
      "Fact: <Paris> <country> <France> .\n",
      "I found the country where the Eiffel Tower is located, which is France.\n",
      "Fact: <France> <capital> <Paris> .\n",
      "I found the capital of the country where the Eiffel Tower is located, which is Paris.\n",
      "Final answer: Paris.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for i in range(out.shape[0]):\n",
    "    print('-'*30, sum(out[i][len(inputs.input_ids[0]):]), len(out[i][len(inputs.input_ids[0]):]))\n",
    "    print(tokenizer.decode(out[i][len(inputs.input_ids[0]):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9631cc0d-16d8-4d61-abeb-877401641bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 'Paris.\\n<|endoftext|>')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop, ans = getanswer.get_answer(out[0])\n",
    "stop, tokenizer.decode(list(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e6715d50-7ca7-4b51-965b-25f05e8dec2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  529,  2177,   275, 29958,   529,  5479, 29958,   529, 29943,   562,\n",
       "        18857,   310, 27529,   310,  4526, 13111,  4926, 29958,   869,    13,\n",
       "        17028, 29901,   529,  2177,   275, 29958,   529,  5479, 29958,   529,\n",
       "        29943,   562, 18857,   310, 27529,   310,  4526, 13111,  4926, 29958,\n",
       "          869,    13,    13, 22550, 29901,  4526, 13111,  4926,    13, 22550,\n",
       "        29901,  3681,    13,    13,  1576,  1139,   338, 29901,  8449,  4272,\n",
       "          338,   278,  7483,   310,   278,  4234,   988,   278,  6371,   321,\n",
       "         2593,   295,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598,\n",
       "          278,  4234,   988,   278,  6371,   321,  2593,   295,   338,  5982,\n",
       "        29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,   310,\n",
       "          393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099, 29892,\n",
       "          591,   508, 10115,   393, 29901,    13, 29899,  3681,   338,  5982,\n",
       "          297,  3444, 29889,    13, 29899,   450,  7483,   310,  3444,   338,\n",
       "         3681, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         3681, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278, 23615,\n",
       "          310,   349,  8069,   338, 29973,    13,  1576, 24481,  1889,  2729,\n",
       "          373,   278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,\n",
       "         1598,   278,  4234,   988,   278, 23615,   310,   349,  8069,   338,\n",
       "         5982, 29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,\n",
       "          310,   393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099,\n",
       "        29892,   591,   508, 10115,   393, 29901,    13, 29899,   450, 23615,\n",
       "          310,   349,  8069,   338,  5982,   297, 12730, 29889,    13, 29899,\n",
       "          450,  7483,   310, 12730,   338,  9184, 29889,    13,    13,  8439,\n",
       "         1079, 29892,   278,  1234,   338,  9184, 29889,    13,    13,    13,\n",
       "         1576,  1139,   338, 29901,  8449,  4272,   338,   278,  7483,   310,\n",
       "          278,  4234,   988,   278,  1530,   359,   344,   398,   338, 29973,\n",
       "           13,  1576, 24481,  1889,  2729,   373,   278,  3367,  2701,   338,\n",
       "        29901,    13, 29896, 29889, 13355,  1598,   278,  4234,   988,   278,\n",
       "         1530,   359,   344,   398,   338,  5982, 29889,    13, 29906, 29889,\n",
       "         5953,   837,   457,   278,  7483,   310,   393,  4234, 29889,    13,\n",
       "           13,  4591,   278,  2183, 17099, 29892,   591,   508, 10115,   393,\n",
       "        29901,    13, 29899,   450,  1530,   359,   344,   398,   338,  5982,\n",
       "          297, 12730, 29889,    13, 29899,   450,  7483,   310, 12730,   338,\n",
       "         9184, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         9184, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278,  7255,\n",
       "        10759,   275,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[i][len(inputs.input_ids[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7bac3e83-317b-4567-9399-e32ff32a8e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9dae38e1-bf69-4794-b380-e1404bfd079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22550, 29901]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2797739d-ffac-4984-9e8d-c4d78c43e62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: Montpellier\\nAnswer: Paris\\n\\nThe question'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([22550, 29901,  4526, 13111,  4926,    13, 22550,\n",
    "        29901,  3681,    13,    13,  1576,  1139])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b4f714b8-71bb-42b0-8fcb-c01ba1350d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  529,  2177,   275, 29958,   529,  5479, 29958,   529, 29943,   562,\n",
       "        18857,   310, 27529,   310,  4526, 13111,  4926, 29958,   869,    13,\n",
       "        17028, 29901,   529,  2177,   275, 29958,   529,  5479, 29958,   529,\n",
       "        29943,   562, 18857,   310, 27529,   310,  4526, 13111,  4926, 29958,\n",
       "          869,    13,    13, 22550, 29901,  4526, 13111,  4926,    13, 22550,\n",
       "        29901,  3681,    13,    13,  1576,  1139,   338, 29901,  8449,  4272,\n",
       "          338,   278,  7483,   310,   278,  4234,   988,   278,  6371,   321,\n",
       "         2593,   295,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598,\n",
       "          278,  4234,   988,   278,  6371,   321,  2593,   295,   338,  5982,\n",
       "        29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,   310,\n",
       "          393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099, 29892,\n",
       "          591,   508, 10115,   393, 29901,    13, 29899,  3681,   338,  5982,\n",
       "          297,  3444, 29889,    13, 29899,   450,  7483,   310,  3444,   338,\n",
       "         3681, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         3681, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278, 23615,\n",
       "          310,   349,  8069,   338, 29973,    13,  1576, 24481,  1889,  2729,\n",
       "          373,   278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,\n",
       "         1598,   278,  4234,   988,   278, 23615,   310,   349,  8069,   338,\n",
       "         5982, 29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,\n",
       "          310,   393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099,\n",
       "        29892,   591,   508, 10115,   393, 29901,    13, 29899,   450, 23615,\n",
       "          310,   349,  8069,   338,  5982,   297, 12730, 29889,    13, 29899,\n",
       "          450,  7483,   310, 12730,   338,  9184, 29889,    13,    13,  8439,\n",
       "         1079, 29892,   278,  1234,   338,  9184, 29889,    13,    13,    13,\n",
       "         1576,  1139,   338, 29901,  8449,  4272,   338,   278,  7483,   310,\n",
       "          278,  4234,   988,   278,  1530,   359,   344,   398,   338, 29973,\n",
       "           13,  1576, 24481,  1889,  2729,   373,   278,  3367,  2701,   338,\n",
       "        29901,    13, 29896, 29889, 13355,  1598,   278,  4234,   988,   278,\n",
       "         1530,   359,   344,   398,   338,  5982, 29889,    13, 29906, 29889,\n",
       "         5953,   837,   457,   278,  7483,   310,   393,  4234, 29889,    13,\n",
       "           13,  4591,   278,  2183, 17099, 29892,   591,   508, 10115,   393,\n",
       "        29901,    13, 29899,   450,  1530,   359,   344,   398,   338,  5982,\n",
       "          297, 12730, 29889,    13, 29899,   450,  7483,   310, 12730,   338,\n",
       "         9184, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         9184, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278,  7255,\n",
       "        10759,   275,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][len(inputs.input_ids[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "efb8c7ce-36ef-451f-a05b-c17a49a9dab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[673, 29901]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "303b7a3f-bd93-4eab-8787-53605cdab198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "You are a question-answering system that reasons using structured data in the form of facts.\n",
      "Given an input question, you generate a concise single answer based on knowledge facts.\n",
      "Follow this format:\n",
      "\n",
      "Question: The question to be answered.\n",
      "Facts for the reasoning process: some facts containing entities, relationships, and values relevant to the question.\n",
      "Long answer: the reasoning process you followed to reach the answer also based on the facts.\n",
      "Answer: the concise answer.\n",
      "\n",
      "Example:\n",
      "Question: Is Mont Blanc taller than Mount Rainier?\n",
      "Facts for the reasoning process:\n",
      "fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
      "fact: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
      "Long answer: Basing on the evidence that the elevation above sea level of Mont Blanc (4,807.02±0.5 metres) is greater than the elevation above sea level of Mount Rainier (4,389 metres), Mont Blanc is taller than Mount Rainier.\n",
      "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "As you can see in the example, triples generally start with information contained in the question and provide additional information.\n",
      "Unfortunately, some of the retrieved facts may irrelevant. You should ignore these irrelevant triples.\n",
      "\n",
      "\n",
      "Now, answer the following question:\n",
      "Question: Which city is the capital of the country where the Eiffel Tower is located?\n",
      "Triples for the reasoning process:\n",
      "fact: <Paris> <location> <Faculty of Medicine of Montpellier> .\n",
      "fact: <Eiffel Tower> <location> <Champ de Mars> .\n",
      "fact: <France> <location> <Cleveland Museum of Art> .\n",
      "fact: <Cleveland Museum of Art> <location> <Wade Park> .\n",
      "fact: <Paris> <location> <Walker Art Gallery> .\n",
      "fact: <France> <location\n"
     ]
    }
   ],
   "source": [
    "for i in range(out.shape[0]):\n",
    "    print('-'*30)\n",
    "    print(tokenizer.decode(out[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf2cf3-b9fa-4914-8827-667ef61d6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([8654])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c3455fb0-727b-44a5-b62e-def03e4cc0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<s> </<s> < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <</reality>> <has characteristic> <indie game> .'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([529,     1,  1533,     1,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          829,   276,  2877,  6778,   529,  5349, 17443, 29958,   529,   513,\n",
    "          347,  3748, 29958,   869])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1f4f3cc4-49f7-440c-ac7d-2890916385b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2360e908-c1c9-4535-ad4d-dd786ca6a018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29901,   529,     1,  1533,     1,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   829,   276,  2877,  6778,   529,  5349, 17443, 29958,   529,\n",
       "          513,   347,  3748, 29958,   869,    13,  3626,   552, 29901,   529,\n",
       "         8654,   264, 13061,   278, 10470, 21869,   313, 29896, 29929, 29900,\n",
       "        29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900,\n",
       "        29906, 15410,   529,  8758,   310, 29958,   529, 29886,   475,  1259,\n",
       "        29958,   869,    13,  3626,   552, 29901,   529,  8654,   264, 13061,\n",
       "          278, 10470, 21869,   313, 29896, 29929, 29900, 29900, 29905, 29884,\n",
       "        29906, 29900, 29896, 29941, 29906, 29900, 29900, 29906, 15410,   529,\n",
       "         8758,   310, 29958,   529, 29886,   475,  1259, 29958,   869,    13,\n",
       "         3626,   552, 29901,   529,  8654,   264, 13061,   278, 10470, 21869,\n",
       "          313, 29896, 29929, 29900, 29900, 29905, 29884, 29906, 29900, 29896,\n",
       "        29941, 29906, 29900, 29900, 29906, 15410,   529,  8758,   310, 29958,\n",
       "          529, 29886,   475,  1259, 29958,   869,    13,  3626,   552, 29901,\n",
       "          529,  8654,   264, 13061,   278, 10470, 21869,   313, 29896, 29929,\n",
       "        29900, 29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900,\n",
       "        29900, 29906, 15410,   529,  8758,   310, 29958,   529, 29886,   475,\n",
       "         1259, 29958,   869,    13,  3626,   552, 29901,   529,  8654,   264,\n",
       "        13061,   278, 10470, 21869,   313, 29896, 29929, 29900, 29900, 29905,\n",
       "        29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900, 29906, 15410,\n",
       "          529,  8758,   310, 29958,   529, 29886,   475,  1259, 29958,   869,\n",
       "           13,  3626,   552, 29901,   529,  8654,   264, 13061,   278, 10470,\n",
       "        21869,   313, 29896, 29929, 29900, 29900, 29905, 29884, 29906, 29900,\n",
       "        29896, 29941, 29906, 29900, 29900, 29906, 15410,   529,  8758,   310,\n",
       "        29958,   529, 29886,   475,  1259, 29958,   869,    13,  3626,   552,\n",
       "        29901,   529,  8654,   264, 13061,   278, 10470, 21869,   313, 29896,\n",
       "        29929, 29900, 29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906,\n",
       "        29900, 29900, 29906, 15410,   529,  8758,   310, 29958,   529, 29886,\n",
       "          475,  1259, 29958,   869,    13,  3626,   552, 29901,   529,  8654,\n",
       "          264, 13061,   278, 10470, 21869,   313, 29896, 29929, 29900, 29900,\n",
       "        29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900, 29906,\n",
       "        15410,   529,  8758,   310, 29958,   529, 29886,   475,  1259, 29958,\n",
       "          869,    13,  3626,   552, 29901,   529,  8654,   264, 13061,   278,\n",
       "        10470, 21869,   313, 29896, 29929, 29900, 29900, 29905, 29884, 29906,\n",
       "        29900, 29896, 29941, 29906, 29900, 29900, 29906, 15410,   529,  8758,\n",
       "          310, 29958,   529, 29886,   475,  1259, 29958,   869,    13,  3626,\n",
       "          552, 29901,   529,  8654,   264, 13061,   278, 10470, 21869,   313,\n",
       "        29896, 29929, 29900, 29900, 29905, 29884, 29906, 29900, 29896, 29941,\n",
       "        29906, 29900, 29900, 29906, 15410,   529,  8758,   310, 29958,   529,\n",
       "        29886,   475,  1259, 29958,   869,    13,  3626,   552, 29901,   529,\n",
       "         8654,   264, 13061,   278, 10470, 21869,   313, 29896, 29929, 29900,\n",
       "        29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900,\n",
       "        29906, 15410,   529,  8758,   310, 29958,   529, 29886,   475,  1259,\n",
       "        29958], device='cuda:0')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][len(inputs.input_ids[0])-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929068f-39be-42cd-acda-832ec2e09543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a4bfa-3829-437f-bdfa-84635b209d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935844e3-47d6-401e-9d80-6c22e6bf171f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c65029-237e-4c91-a890-9f50463d0191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f01d61-ef9d-40b0-b06c-00f392c51dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f4d8d-ae1e-40b1-8d84-7acdb88ada61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "48a66043-2df7-4622-bf26-0da8a872199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unconstrained\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # TODO put tqdm as a streamer\n",
    "    out = model.generate(\n",
    "        input_ids = inputs.input_ids,\n",
    "        output_scores=True,\n",
    "        #logits_processor=logits_processor_list,\n",
    "        max_new_tokens=100,\n",
    "        streamer = None,\n",
    "        do_sample = True,\n",
    "        top_k=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dd880692-e9b6-49e7-b5ed-e17c592165d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a question-answering system that reasons using structured data in the form of triples.\n",
      "Given an input question, you generate a concise a single answer based on knowledge triples.\n",
      "Follow this format:\n",
      "\n",
      "Question: The question to be answered.\n",
      "Triples for the reasoning process: some triples containing entities, relationships, and values relevant to the question.\n",
      "Long answer: the reasoning process you followed to reach the answer also based on the triples.\n",
      "Answer: the concise answer.\n",
      "\n",
      "Example:\n",
      "Question: Is Mont Blanc taller than Mount Rainier?\n",
      "Triples for the reasoning process:\n",
      "triple: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
      "triple: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
      "Long answer: Basing on the evidence that the elevation above sea level of Mont Blanc (4,807.02±0.5 metres) is greater than the elevation above sea level of Mount Rainier (4,389 metres), Mont Blanc is taller than Mount Rainier.\n",
      "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "As you can see in the example, triples generally start with information contained in the question and provide additional information.\n",
      "Unfortunately, some of the retrieved triples may irrelevant. You should ignore these irrelevant triples.\n",
      "\n",
      "\n",
      "Now, answer the following question:\n",
      "Question: Which is the capital of Burundi?\n",
      "Triples for the reasoning process:\n",
      "triple: <Burundi> <type> <country>,\n",
      "triple: <Burundi> <capital> <name of capital>,\n",
      "triple: <Kigali> <is capital of> <country> ,\n",
      "triple: <name of capital> <is capital of> <country>,\n",
      "triple: <Kigali> <location> <country>,\n",
      "triple: <Kigali> <location> <region>,\n",
      "triple:\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f0029971-9a5b-424b-b361-e07d0be8bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3626, 552, 29901]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2a5bd8b5-b4b7-4989-862e-e773891a4fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3626,   552, 29901,   529, 21140, 29887,  1974, 29958,   529,  5479,\n",
       "        29958,   529, 15654, 29958,   869,    13,  3626,   552, 29901,   529,\n",
       "        29940,  1979,  5252, 29958,   529, 11466,   292, 29958,   529, 21140,\n",
       "        29887,  1974, 29958,   869,    13,  3626,   552, 29901,   529, 29931,\n",
       "         1314,  1590, 18041, 29958,   529, 11466,   292, 29958,   529, 21140,\n",
       "        29887,  1974, 29958,   869,    13,  3626,   552, 29901,   529, 29954,\n",
       "          837,  1384, 29958,   529, 11466,   292, 29958,   529, 21140, 29887,\n",
       "         1974, 29958,   869,    13,  3626,   552, 29901,   529, 29909,   504,\n",
       "         2849, 29958,   529, 11466,   292, 29958,   529, 21140, 29887,  1974,\n",
       "        29958,   869,    13,  3626,   552, 29901,   529, 29940,  1979,  5252],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][len(inputs.input_ids[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f10ae26f-6ad2-4531-a7df-047a7816fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Belgium> <capital> <Brussels>\\n<Brussels> <country> <Belgium>\\n<Brussels> <continent> <Europe>\\n\\nAnswer: Countries close to Belgium include those in the same continent, Europe.\\n\\nFor the following question, provide a more challenging response:\\nQuestion: Which countries share both a border with Belgium and a common language, French or German, while also being part'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out[0][len(inputs.input_ids[0]):-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffa6eb42-8af9-4113-b891-15a6de7abad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tri <'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([8602,529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28c5f4f9-b129-4b4b-ae31-bb6b10a7d3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [8602, 2701, 363, 278, 24481, 1889, 29901, 13, 29966, 21140, 29887, 1974, 29958, 529, 5030, 2410, 29958, 529, 12432, 1558, 1379, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 13509, 29958, 529, 21140, 29887, 1974, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 1285, 8946, 29958, 529, 15654, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('''Triples for the reasoning process:\n",
    "<Belgium> <capital> <Brussels>\n",
    "<Brussels> <country> <Belgium>\n",
    "<Brussels> <continent> <Europe>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d2ec2fa-cef5-4e5c-b412-777aa1078c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [29871, 13, 29966, 21140, 29887, 1974, 29958, 529, 5030, 2410, 29958, 529, 12432, 1558, 1379, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 13509, 29958, 529, 21140, 29887, 1974, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 1285, 8946, 29958, 529, 15654, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('''\n",
    "<Belgium> <capital> <Brussels>\n",
    "<Brussels> <country> <Belgium>\n",
    "<Brussels> <continent> <Europe>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9991f9d-c62c-4dc9-bae9-3b7598d82651",
   "metadata": {},
   "source": [
    "# Debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4b2bc029-da57-4587-95db-0acf153b247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_endswith( seq1, seq2):\n",
    "    if len(seq2) == 0:\n",
    "        return False\n",
    "    subseq1 = seq1[-len(seq2):]\n",
    "    return subseq1 == seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c3d0c64f-2733-4b5e-a020-bd82ba30192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "83207086-31f6-4442-90fa-2bae65298ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_endswith(list(range(10)), [7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab4ab194-8cb3-4f4e-beab-d4db0a8ede46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8758, 2072, 735]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrie.next_tokens([0, 29871, 529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330a429b-96f5-4cc7-b4b5-048ce35e0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ctrie_Phi-3-mini-128k-instruct.pickle', 'rb') as fd:\n",
    "    ctrie_load = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab56518-c36c-4996-ba7c-1ae6c8495078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 18252, 6319, 3705, 1533, 3532, 5277, 15271, 20577, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrie_load.next_tokens([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34102090-05db-4f21-9042-e09ba780caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DonToMPermTw=>41CPtAnydist>JustLSPABLOXAmLABKpeSchHMatFESHETrO'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ctrie_load.next_tokens([18252,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d311b6e6-168f-425d-b0f9-419c86dabeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'< <! <? <- </ << <= <> <%<unk>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ctrie_load.next_tokens([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeabf7b-fd69-499e-af62-e29bdbbfb96f",
   "metadata": {},
   "source": [
    "# Da dove arrivano i non '<'???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3ba013ff-23d4-48bf-bdd7-74f59e3a2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a6e794a3-9d47-41e9-8f7f-c712126f9fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Belouga> <country of registry> <Belize> .'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [529, 21140]\n",
    "for i in range(100):\n",
    "    next_tokens = ctrie_load.next_tokens(seq)\n",
    "\n",
    "    # choice\n",
    "    if next_tokens:\n",
    "        if rand:\n",
    "            chosen_token = random.choice(next_tokens)\n",
    "        else:\n",
    "            chosen_token = next_tokens[0]\n",
    "        \n",
    "\n",
    "        seq.append(chosen_token)\n",
    "    else:\n",
    "        assert ctrie_load.reached_leaf(seq)\n",
    "        break\n",
    "\n",
    "tokenizer.decode(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eeec6503-dcf9-4f14-b104-295f1cea2b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 21140, 346, 29905, 29884, 29900, 29906, 29896, 29929, 2034]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ef976-a62a-4930-b403-290cd2e97904",
   "metadata": {},
   "source": [
    "# Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e5d13639-e0d1-4168-adca-2a2d8d96f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_str = '<Belce\\\\u0219ti> <located in the administrative territorial entity> <Pogone\\\\u0219ti> .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb832f54-780c-4dc7-bca5-3c0a9cb5c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Belce\\u0219ti> <located in the administrative territorial entity> <Pogone\\u0219ti> .\n"
     ]
    }
   ],
   "source": [
    "print(unicode_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5580dd-59f9-4339-bde7-0ace875113da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Italo Balbo> <allegiance> <Kingdom of Italy> .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([529,\n",
    " 3112,\n",
    " 7003,\n",
    " 7392,\n",
    " 833,\n",
    " 29958,\n",
    " 529,\n",
    " 284,\n",
    " 1397,\n",
    " 8837,\n",
    " 29958,\n",
    " 529,\n",
    " 29968,\n",
    " 292,\n",
    " 3129,\n",
    " 310,\n",
    " 12730,\n",
    " 29958,\n",
    " 869]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050f1883-f89a-4cb8-acbc-67d14d5410fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 529,\n",
       " 29885,\n",
       " 9693,\n",
       " 29958,\n",
       " 529,\n",
       " 2525,\n",
       " 537,\n",
       " 3732,\n",
       " 9324,\n",
       " 29958,\n",
       " 869]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize('<Belgium> <motto> <Unity makes strength> .'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42480264-43a7-4a9e-ba35-e5203d550f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sujeonggwa> <subclass of> <punch> .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([60000, 529, 2146, 1324, 549, 29887, 2766, 29958, 529, 1491, 1990, 310, 29958, 529, 29886, 3322, 29958, 869])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "750e9cc1-1755-4f99-b3a1-71f650c0e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [60000, 6319, 313, 29943, 6617, 5185, 264, 15410, 529, 689, 689, 310, 907, 1230, 664, 29958, 529, 12073, 3769, 29958, 869, 29958,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f6e511c-46e0-41d0-8224-0b282ae2a3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<? (Fragezeichen)> <formform of creative work> <studio album> .>'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(arr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d243759-c0e2-4f18-ab79-365d36602c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18252, 10310, 1089, 29893, 2353, 29934, 29991, 29958, 529]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83f59363-f68e-4293-add0-ef41d4ee3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "into = tokenizer(\"<Belgium>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a3b6fe7-e27e-4584-bef1-558cc192da26",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m into\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "print(into.pop(0))\n",
    "into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b18a548f-43de-46bf-815b-4ee7f9263a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 529,\n",
       " 13010,\n",
       " 29915,\n",
       " 29879,\n",
       " 1667,\n",
       " 7494,\n",
       " 25792,\n",
       " 29958,\n",
       " 529,\n",
       " 2290,\n",
       " 284,\n",
       " 29901,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 869]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<Belgium> <topic's main Wikimedia portal> <Portal:Belgium> .\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1008d8fb-d1bf-4a12-b1f4-89a35ed84a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [529, 29882, 932, 3335, 29958, 529, 29881, 15622, 515, 29958, 529, 29943, 295, 293, 3943, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('<happiness> <different from> <Felicità>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2917132-7665-44f9-a127-09ccdc357e57",
   "metadata": {},
   "source": [
    "## Unicode problems\n",
    "<happiness> <described by source> <Encyclop\\u00E6dia Britannica 11th edition> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed6f9f2e-c374-4bd2-8420-74f26148750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_uniproblem_str = '<happiness> <described by source> <Encyclop\\u00E6dia Britannica 11th edition> .'\n",
    "happiness_uniproblem = [529, 29882, 932, 3335, 29958, 529, 2783, 23059, 491, 2752, 29958, 529, 2369, 8798, 4757, 29905, 29884, 29900, 29900, 29923, 29953, 15321, 18940, 29871, 29896, 29896, 386, 12203, 29958, 869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80d48311-426e-429e-993e-b3449d6e9313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<happiness> <described by source> <Encyclopædia Britannica 11th edition> .\n"
     ]
    }
   ],
   "source": [
    "print(happiness_uniproblem_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0c8a49e-35a3-4963-9408-f024c5039b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<happiness> <described by source> <Encyclopædia Britannica 11th edition> .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_uniproblem_str.encode('latin1').decode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa8edcc3-7a47-4577-9cf8-4fa3bb78ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7707ec85-7a98-4315-9a4a-98b530e30616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<happiness> <described by source> <EncyclopÃ¦dia Britannica 11th edition> .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codecs.decode(happiness_uniproblem_str, 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dea8176f-4e8a-4f48-9c20-5a31e6dd358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\\\u' in mstr.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7772d513-5bba-43a4-84bb-0149181e0ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_uniproblem_str[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "96ba7604-43ab-44d2-aa14-476d037fff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstr = tokenizer.decode(happiness_uniproblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff7faf5d-5ec7-498f-9f5f-48f2f1c109fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁<',\n",
       " 'h',\n",
       " 'app',\n",
       " 'iness',\n",
       " '>',\n",
       " '▁<',\n",
       " 'des',\n",
       " 'cribed',\n",
       " '▁by',\n",
       " '▁source',\n",
       " '>',\n",
       " '▁<',\n",
       " 'En',\n",
       " 'cyc',\n",
       " 'lop',\n",
       " '\\\\',\n",
       " 'u',\n",
       " '0',\n",
       " '0',\n",
       " 'E',\n",
       " '6',\n",
       " 'dia',\n",
       " '▁Britannica',\n",
       " '▁',\n",
       " '1',\n",
       " '1',\n",
       " 'th',\n",
       " '▁edition',\n",
       " '>',\n",
       " '▁.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(happiness_uniproblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc1904fe-2b27-4f03-b54e-ef769c648c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/data/props.json') as fd:\n",
    "    obj = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daf16236-8f69-4e29-b032-27ce3cf3743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "obj = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eecf2d22-8d4f-4672-a9a5-ee84356e0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 {'datatype': 'external-id', 'id': 'P11322', 'label': '18th Century Russian Dictionary ID', 'description': 'identifier for a lexeme in the Словарь русского языка XVIII века (1984-1991) as hosted on the Fundamental Electronic Library of Russian Literature and Folklore', 'aliases': [], 'types': []}\n"
     ]
    }
   ],
   "source": [
    "for i,ob in enumerate(obj):\n",
    "    if 'Russian Literature' in ob['description']:\n",
    "        print(i, ob)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99fc95c6-26b4-44c2-99f6-15bcc92977b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'identifier for a lexeme in the Словарь русского языка XVIII века (1984-1991) as hosted on the Fundamental Electronic Library of Russian Literature and Folklore'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[10]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7b40e-93ed-40a7-91c6-f32ec65fafc6",
   "metadata": {},
   "source": [
    "## Verify titles conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3bda8245-efb0-4447-815e-fbc3a001fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/workspace/data/wikidata_titles_mapping.pickle', 'rb') as fd:\n",
    "    title_mappings = pickle.load(fd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e6c01fa-dd22-46c1-95ff-82228703f6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6199"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(title_mappings.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9bd7466f-b345-4213-911d-52f3b5d40eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_mapping = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ab70abc6-16f0-4587-a5f7-55760eedd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in title_mappings.items():\n",
    "    if v not in inverted_mapping:\n",
    "        inverted_mapping[v] = []\n",
    "    inverted_mapping[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "72bc53be-7d51-45ba-ad75-292d5012b130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5846104"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3f368c5-a061-4bc9-a38f-d40eb7f5d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('Anarchism', [6199])\n"
     ]
    }
   ],
   "source": [
    "for i,(k,v) in enumerate(inverted_mapping.items()):\n",
    "    if len(v) > 0:\n",
    "        print(i, (k,v))\n",
    "        break\n",
    "#found categories, portal, template. can I remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba8e44aa-ba52-43cb-97aa-1f3d7e8512b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [len(v) for v in inverted_mapping.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6da3705f-4772-49a8-bb5d-9506624fc555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b0fc755-b89d-492f-a65a-110b9cab9908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14f75fb1-6dcd-4f37-a3dd-e241b9eaf604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "68883645-caf0-457d-a6f6-f03e889ae083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5adfd2be-9226-4303-968b-11a52f7cba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c7dba36-b14d-4585-86f5-cda5196356b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.0), np.float64(1.0))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(stats, 0.97), np.quantile(stats, 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "395d5777-9148-40f7-a6ad-3cdcc9e5cff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5846104, 0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats), sum(l for l in stats if l > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "82e5f739-8467-4716-ab3a-b36276aab3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous = {k:v for k,v in inverted_mapping.items() if len(v) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22891768-b5c3-42c1-9d4e-7e25874e1fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "af59d9a2-4b29-4074-a1c9-fe8e6e4326f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'who am i?',\n",
    "    'was ist das?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4a74110d-9b53-4186-a909-151ea983cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encoding = tokenizer(\n",
    "    questions,              # Input list of questions\n",
    "    padding=True,           # Pad to the longest sequence in the batch\n",
    "    truncation=True,        # Truncate to the model's maximum input length\n",
    "    return_tensors=\"pt\",     # Return PyTorch tensors (use 'tf' for TensorFlow)\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5768599c-3f06-4930-97a5-9d0c971769f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "71df8557-bac7-42ae-9b3b-b26035af095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1058,   626,   474, 29973],\n",
       "        [  471,  1752,  1697, 29973]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "3e71e81f-643f-4738-8a14-5123d755f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 2.2942285537719727\n",
      "[\"You are a helpful assistant. Help me to write a blogpost about travelling. Here's the raw content:\\n\\nTraveling is an incredible way to broaden\", 'You are a helpful assistant. What is the capital of France? \\n<|assistant|>']\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DynamicCache, StaticCache\n",
    "\n",
    "'''\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "'''\n",
    "# Init StaticCache with big enough max-length (1024 tokens for the below example)\n",
    "# You can also init a DynamicCache, if that suits you better\n",
    "prompt_cache = DynamicCache() #(config=model.config, max_batch_size=1, max_cache_len=1024, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "INITIAL_PROMPT = \"You are a helpful assistant. \"\n",
    "inputs_initial_prompt = tokenizer(INITIAL_PROMPT, return_tensors=\"pt\").to(\"cuda\")\n",
    "# This is the common prompt cached, we need to run forward without grad to be abel to copy\n",
    "with torch.no_grad():\n",
    "     prompt_cache = model(**inputs_initial_prompt, past_key_values = prompt_cache).past_key_values\n",
    "\n",
    "prompts = [\"Help me to write a blogpost about travelling.\", \"What is the capital of France?\"]\n",
    "responses = []\n",
    "start = time.time()\n",
    "for prompt in prompts:\n",
    "    new_inputs = tokenizer(INITIAL_PROMPT + prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    past_key_values = copy.deepcopy(prompt_cache)\n",
    "    outputs = model.generate(**new_inputs, max_new_tokens=20, past_key_values=past_key_values,)\n",
    "    response = tokenizer.batch_decode(outputs)[0]\n",
    "    responses.append(response)\n",
    "\n",
    "print('elapsed', time.time() - start)\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "66115913-8049-4fc1-9eaf-415fc738383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 1, 30, 13, 52, 21, 27693, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now(datetime.timezone.utc)\n",
    "now.strftime(\"%d/%m/%Y %H:%M:%S UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b580de40-4d71-46f0-afc7-4ccd854ea07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": 1, \"b\": 2}'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps({'a':1,'b':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2c5ff-2a6f-44ac-8c71-aab654b2d6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fde6fe4-929d-4ed6-8e98-ffb956cb2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_answer = '''Reasoning: I need to find the name of the protagonist in the game God of War.\n",
    "Fact: <God of War> <characters> <Kratos> .\n",
    "I found the name of the protagonist in the game God of War. Now I can provide an answer.\n",
    "Long answer: The protagonist of God of War is Kratos.\n",
    "Final answer: Kratos.\n",
    "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8409fa80-9912-44b6-9878-22323f1faa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "getanswer.set_prompt([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48a325c6-39cb-46bc-9ea7-c8588ca0c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 399\n",
      "- 1 399\n",
      "- 2 399\n",
      "- 3 399\n",
      "- 4 399\n",
      "- 5 399\n",
      "- 6 399\n",
      "- 7 399\n",
      "- 8 399\n",
      "- 9 399\n",
      "- 10 399\n",
      "- 11 399\n",
      "- 12 399\n",
      "- 13 399\n",
      "- 14 399\n",
      "- 15 399\n",
      "- 16 399\n",
      "- 17 399\n",
      "- 18 399\n",
      "- 19 399\n",
      "- 20 399\n",
      "- 21 399\n",
      "- 22 399\n",
      "- 23 399\n",
      "- 24 399\n",
      "- 25 399\n",
      "- 26 399\n",
      "- 27 399\n",
      "- 28 399\n",
      "- 29 399\n",
      "- 30 399\n",
      "- 31 399\n",
      "- 32 399\n",
      "- 33 399\n",
      "- 34 399\n",
      "- 35 399\n",
      "- 36 399\n",
      "- 37 399\n",
      "- 38 399\n",
      "- 39 399\n",
      "- 40 399\n",
      "- 41 399\n",
      "- 42 399\n",
      "- 43 399\n",
      "- 44 399\n",
      "- 45 399\n",
      "- 46 399\n",
      "- 47 399\n",
      "- 48 399\n",
      "- 49 399\n",
      "- 50 399\n",
      "- 51 399\n",
      "- 52 399\n",
      "- 53 399\n",
      "- 54 399\n",
      "- 55 399\n",
      "- 56 399\n",
      "- 57 399\n",
      "- 58 399\n",
      "- 59 399\n",
      "- 60 399\n",
      "- 61 399\n",
      "- 62 399\n",
      "- 63 399\n",
      "- 64 399\n",
      "- 65 399\n",
      "- 66 399\n",
      "- 67 399\n",
      "- 68 399\n",
      "- 69 399\n",
      "- 70 399\n",
      "- 71 399\n",
      "- 72 399\n",
      "- 73 399\n",
      "- 74 399\n",
      "- 75 399\n",
      "- 76 399\n",
      "- 77 399\n",
      "- 78 399\n",
      "- 79 399\n",
      "- 80 399\n",
      "= 0\n",
      "- 81 399\n",
      "= 1\n",
      "- 82 399\n",
      "= 2\n",
      "+ 83\n",
      "+ 84\n",
      "+ 85\n",
      "+ 86\n",
      "+ 87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, [476, 3605, 359, 29889])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getanswer.get_answer(tokenizer.encode(debug_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaec3f7a-69fd-44e7-91cd-1fee34eeb8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15790, 1234, 29901]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getanswer.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d86f1afa-793d-4aa9-a01c-24a7b1ee1832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kratos.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([476, 3605, 359, 29889]\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda base)",
   "language": "python",
   "name": "condabase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
