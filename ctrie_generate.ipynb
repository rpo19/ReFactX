{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2520170d-3c75-404e-a61b-375d5bbb5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bitsandbytes accelerate flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d437cde-8966-4a9d-b72d-a45549d6c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494b6997-63c2-4f63-b880-fd2520c829bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import time\n",
    "from IPython.display import JSON\n",
    "import sys\n",
    "sys.settrace(None)\n",
    "import pdb\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer, StoppingCriteria, StoppingCriteriaList #, CodeGenTokenizer\n",
    "from transformers.generation.logits_process import LogitsProcessorList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3beccbb-aa32-4dae-9ed5-6193fba6d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255d12e2-f799-4897-a15f-d1fdc285c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03167244-77c4-41b6-9698-7d9b412c1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27aeab6-d6d9-47b5-ad49-1357ce197eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgresql_connection = psycopg.connect('postgres://postgres:secret@10.0.0.118:5432/postgres', autocommit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d58190-e8d0-4ee8-b16a-e0b59f9b6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4432e09-49df-4af6-a17a-d2348ff2cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootkey = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567e0bb8-1be5-4fef-9652-504d64d1c5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0364e3f4-c364-476c-8a35-1986335c8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rootkey > max(tokenizer.vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa01da77-361d-4ace-936e-55f04d335349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e82adf2-cc46-403b-93e0-523d127b2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a991d2e-78df-48e9-a0b6-19e148cd20c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             trust_remote_code=True,\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             low_cpu_mem_usage=True,\n",
    "                                             #attn_implementation=\"flash_attention_2\",\n",
    "                                             #attn_implementation=\"flash_attention\",\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c6645b9-3be0-4b57-9fcc-138a93e4c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.device.type == device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c2b54b3-6c0d-45ee-abdd-dff9f66718ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a question-answering system that reasons using structured data in the form of facts.\n",
    "Given an input question, you generate a concise single answer based on knowledge facts.\n",
    "Follow this format:\n",
    "\n",
    "Question: The question to be answered.\n",
    "Facts for the reasoning process: some facts containing entities, relationships, and values relevant to the question.\n",
    "Long answer: the reasoning process you followed to reach the answer also based on the facts.\n",
    "Answer: the concise answer. After answering please terminate with <|endoftext|>.\n",
    "\n",
    "Example:\n",
    "Question: Is Mont Blanc taller than Mount Rainier?\n",
    "Facts for the reasoning process:\n",
    "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
    "Fact: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
    "Long answer: Basing on the evidence that the elevation above sea level of Mont Blanc (4,807.02±0.5 metres) is greater than the elevation above sea level of Mount Rainier (4,389 metres), Mont Blanc is taller than Mount Rainier.\n",
    "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
    "<|endoftext|>\n",
    "\n",
    "As you can see in the example, triples generally start with information contained in the question and provide additional information.\n",
    "Unfortunately, some of the retrieved facts may irrelevant. You should ignore these irrelevant triples.\n",
    "Remeber to end with <|endoftext|>.\n",
    "\n",
    "\n",
    "Now, answer the following question:\n",
    "Question: {question}\n",
    "Triples for the reasoning process:\n",
    "Fact:'''\n",
    "prompt = '''<|system|>\n",
    "You are a helpful question answering assistant that bases its answer on facts from a knowledge base.\n",
    "1) You receive an input question.\n",
    "2) You reason on the path you need to follow to reach the answer starting from the information in the question.\n",
    "3) You provide the relevant facts useful to reach the answer and you reason on top of them.\n",
    "4) You explain your reasoning process and provide a long answer with your motivations.\n",
    "5) You provide a short concise answer.\n",
    "<|end|>\n",
    "\n",
    "<|user|>\n",
    "Which mountain is taller between Mont Blanc and Mount Rainier?\n",
    "<|end|>\n",
    "\n",
    "<|assistant|>\n",
    "Reasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights and the final answer will be the taller mountain.\n",
    "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 meters> .\n",
    "I found the height of Mont Blanc. I still need the height of Mount Rainier.\n",
    "Fact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\n",
    "I also found the height of Mount Rainier. Now I can compare the heights and provide an answer.\n",
    "Long Answer: Mont Blanc is 4,807 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\n",
    "Answer: Mont Blanc.\n",
    "<|end|>\n",
    "\n",
    "<|user|>\n",
    "{question}\n",
    "<|end|>\n",
    "\n",
    "<|assistant|>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ec60bee-3eba-4cc2-9c66-d5595d27500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a helpful question answering assistant that bases its answer on facts from a knowledge base.\n",
      "1) You receive an input question.\n",
      "2) You reason on the path you need to follow to reach the answer starting from the information in the question.\n",
      "3) You provide the relevant facts useful to reach the answer and you reason on top of them.\n",
      "4) You explain your reasoning process and provide a long answer with your motivations.\n",
      "5) You provide a short concise answer.\n",
      "<|end|>\n",
      "\n",
      "<|user|>\n",
      "Which mountain is taller between Mont Blanc and Mount Rainier?\n",
      "<|end|>\n",
      "\n",
      "<|assistant|>\n",
      "Reasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights and the final answer will be the taller mountain.\n",
      "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 meters> .\n",
      "I found the height of Mont Blanc. I still need the height of Mount Rainier.\n",
      "Fact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\n",
      "I also found the height of Mount Rainier. Now I can compare the heights and prove an answer.\n",
      "Long Answer: Mont Blanc is 4,807 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\n",
      "Answer: Mont Blanc.\n",
      "<|end|>\n",
      "\n",
      "<|user|>\n",
      "{question}\n",
      "<|end|>\n",
      "\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f340e2-8353-4f43-98d6-7e6c82bd4f2a",
   "metadata": {},
   "source": [
    "## Find switch pattern\n",
    "may be tokenizer dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27832621-8b67-4a05-9fa6-251000ed2b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20738, 29901]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fact', ':']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_pattern = tokenizer('''\n",
    "Fact:''').input_ids[2:]\n",
    "print(switch_pattern)\n",
    "tokenizer.convert_ids_to_tokens(switch_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb124606-cd51-4d48-9869-9fa93bf7f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0a7d17f-72f6-4c4f-a27f-90a7edb82774",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_pattern = [20738, 29901] # [3626, 552, 29901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6d9fa421-7175-4aad-b9a2-a3c5b56d0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctrie import PostgresTrieIndex, ConstrainedLogitsProcessor, GetAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d08c2aa0-5493-4e5d-937a-322c5574f0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newline_token = tokenizer('''\n",
    "''').input_ids[-1]\n",
    "newline_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e309ab38-4878-4551-89d7-aa466d13b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "myctrie = PostgresTrieIndex(rootkey=rootkey, postgresql_connection=postgresql_connection, switch_parameter=8, table_name='ctrie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97d9c5e3-f4ad-4953-b297-5f8acd05c10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_token = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "212bdd36-79ce-4026-83a5-cb7f9d103c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    '''Which city is the capital of the country where the Eiffel Tower is?''',\n",
    "    'Who is the father of Barack Obama?'\n",
    "]\n",
    "prompted_texts = [prompt.format(question=question) for question in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompted_texts, return_tensors='pt', padding=True)\n",
    "inputs = inputs.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9a409f46-bce0-4094-8a1f-10e5b0b6a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_processor = ConstrainedLogitsProcessor(index=myctrie, switch_pattern=switch_pattern, end_token=newline_token)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    constrained_processor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33710ffa-cd0c-4de8-988b-0381476366bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20738, 29901]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "602c685e-da3e-4a25-9dfd-25d13664b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29871, 13, 22550, 29901]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22550, 29901]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.encode('''\n",
    "Answer:'''))\n",
    "answer_tokens = [22550, 29901]\n",
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c7ab0233-46eb-47f2-a619-21e9e3ade565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4f759180-6a93-413f-a4bb-bbaa3487b894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 2177, 275, 29958]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<Paris>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "894ebe31-131c-42dc-9e20-5407f42d6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_parentheses_right = 29958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "57a042e4-f2e5-4b96-8063-d30721ccd4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29901, 22550]\n"
     ]
    }
   ],
   "source": [
    "getanswer = GetAnswer(inputs.input_ids[0], answer_tokens, newline_token, angular_parentheses_right, all)\n",
    "stopping_criteria = StoppingCriteriaList([\n",
    "    getanswer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "045a725d-8d4d-45e1-bbcb-981df8f943b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22550, 29901]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 2\n",
    "\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        input_ids = inputs.input_ids,\n",
    "        output_scores=True,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=400,\n",
    "        #streamer = streamer,\n",
    "        #do_sample = True,\n",
    "        #top_k=3,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=1,\n",
    "        #no_repeat_ngram_size=1,\n",
    "        #remove_invalid_values=True,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "89aa77af-f66d-4428-806b-2cb965310062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ tensor(6713741, device='cuda:0') 400\n",
      "Reasoning: I need to find the country where the Eiffel Tower is located, then find the capital of that country.\n",
      "Fact: <Eiffel Tower> <location> <Champ de Mars> .\n",
      "I found the location of the Eiffel Tower. I still need to find the capital of the country where the Eiffel Tower is located.\n",
      "Fact: <Champ de Mars> <country> <France> .\n",
      "I found the country where the Eiffel Tower is located. Now I can find the capital of that country.\n",
      "Fact: <France> <capital> <Paris> .\n",
      "I found the capital of the country where the Eiffel Tower is located. Now I can prove an answer.\n",
      "Long Answer: The Eiffel Tower is located in France, and the capital of France is Paris.\n",
      "Answer: Paris.\n",
      "<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.<|end|><|assistant|> Paris.\n",
      "------------------------------ tensor(3758073, device='cuda:0') 400\n",
      "Reasoning: I need to provide the name of Barack Obama's father, then I need to provide the name of his mother, then I need to provide the name of his biological father.\n",
      "Fact: <Barack Obama> <father> <Barack Obama Sr.> .\n",
      "I found the name of Barack Obama'quer father. I still need the name of Barack Obama's mother.\n",
      "Fact: <Barack Obama> <father> <Barack Obama Sr.> .\n",
      "I found the name of Barack Obama's father. I still need the name of Barack Obama's biological father.\n",
      "Fact: <Barack Obama> <father> <Barack Obama Sr.> .\n",
      "I found the name of Barack Obama's father. I still need the name of Barack Obama's biological father.\n",
      "Fact: <Barack Obama> <father> <Barack Obama Sr.> .\n",
      "I found the name of Barack Obama's father. I still need the name of Barack Obama's biological father.\n",
      "Fact: <Barack Obama> <father> <Barack Obama Sr.> .\n",
      "I found the name of Barack Obama's father. I still need the name of Barack Obama's biological father.\n",
      "Fact: <Barack Obama> <father> <Barack Obama Sr.> .\n",
      "I found the name of Barack Obama's father. I still need the name of Barack Obama's biological father.\n",
      "Fact: <Barack Obama> <father> <Barack Obama Sr.> .\n",
      "I found the name of Barack Obama's father. I still need the name of Barack Obama's biological father.\n",
      "Fact\n"
     ]
    }
   ],
   "source": [
    "for i in range(out.shape[0]):\n",
    "    print('-'*30, sum(out[i][len(inputs.input_ids[0]):]), len(out[i][len(inputs.input_ids[0]):]))\n",
    "    print(tokenizer.decode(out[i][len(inputs.input_ids[0]):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631cc0d-16d8-4d61-abeb-877401641bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop, ans = getanswer.get_answer(out[0])\n",
    "stop, tokenizer.decode(list(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e6715d50-7ca7-4b51-965b-25f05e8dec2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  529,  2177,   275, 29958,   529,  5479, 29958,   529, 29943,   562,\n",
       "        18857,   310, 27529,   310,  4526, 13111,  4926, 29958,   869,    13,\n",
       "        17028, 29901,   529,  2177,   275, 29958,   529,  5479, 29958,   529,\n",
       "        29943,   562, 18857,   310, 27529,   310,  4526, 13111,  4926, 29958,\n",
       "          869,    13,    13, 22550, 29901,  4526, 13111,  4926,    13, 22550,\n",
       "        29901,  3681,    13,    13,  1576,  1139,   338, 29901,  8449,  4272,\n",
       "          338,   278,  7483,   310,   278,  4234,   988,   278,  6371,   321,\n",
       "         2593,   295,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598,\n",
       "          278,  4234,   988,   278,  6371,   321,  2593,   295,   338,  5982,\n",
       "        29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,   310,\n",
       "          393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099, 29892,\n",
       "          591,   508, 10115,   393, 29901,    13, 29899,  3681,   338,  5982,\n",
       "          297,  3444, 29889,    13, 29899,   450,  7483,   310,  3444,   338,\n",
       "         3681, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         3681, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278, 23615,\n",
       "          310,   349,  8069,   338, 29973,    13,  1576, 24481,  1889,  2729,\n",
       "          373,   278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,\n",
       "         1598,   278,  4234,   988,   278, 23615,   310,   349,  8069,   338,\n",
       "         5982, 29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,\n",
       "          310,   393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099,\n",
       "        29892,   591,   508, 10115,   393, 29901,    13, 29899,   450, 23615,\n",
       "          310,   349,  8069,   338,  5982,   297, 12730, 29889,    13, 29899,\n",
       "          450,  7483,   310, 12730,   338,  9184, 29889,    13,    13,  8439,\n",
       "         1079, 29892,   278,  1234,   338,  9184, 29889,    13,    13,    13,\n",
       "         1576,  1139,   338, 29901,  8449,  4272,   338,   278,  7483,   310,\n",
       "          278,  4234,   988,   278,  1530,   359,   344,   398,   338, 29973,\n",
       "           13,  1576, 24481,  1889,  2729,   373,   278,  3367,  2701,   338,\n",
       "        29901,    13, 29896, 29889, 13355,  1598,   278,  4234,   988,   278,\n",
       "         1530,   359,   344,   398,   338,  5982, 29889,    13, 29906, 29889,\n",
       "         5953,   837,   457,   278,  7483,   310,   393,  4234, 29889,    13,\n",
       "           13,  4591,   278,  2183, 17099, 29892,   591,   508, 10115,   393,\n",
       "        29901,    13, 29899,   450,  1530,   359,   344,   398,   338,  5982,\n",
       "          297, 12730, 29889,    13, 29899,   450,  7483,   310, 12730,   338,\n",
       "         9184, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         9184, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278,  7255,\n",
       "        10759,   275,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[i][len(inputs.input_ids[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7bac3e83-317b-4567-9399-e32ff32a8e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9dae38e1-bf69-4794-b380-e1404bfd079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22550, 29901]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2797739d-ffac-4984-9e8d-c4d78c43e62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: Montpellier\\nAnswer: Paris\\n\\nThe question'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([22550, 29901,  4526, 13111,  4926,    13, 22550,\n",
    "        29901,  3681,    13,    13,  1576,  1139])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b4f714b8-71bb-42b0-8fcb-c01ba1350d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  529,  2177,   275, 29958,   529,  5479, 29958,   529, 29943,   562,\n",
       "        18857,   310, 27529,   310,  4526, 13111,  4926, 29958,   869,    13,\n",
       "        17028, 29901,   529,  2177,   275, 29958,   529,  5479, 29958,   529,\n",
       "        29943,   562, 18857,   310, 27529,   310,  4526, 13111,  4926, 29958,\n",
       "          869,    13,    13, 22550, 29901,  4526, 13111,  4926,    13, 22550,\n",
       "        29901,  3681,    13,    13,  1576,  1139,   338, 29901,  8449,  4272,\n",
       "          338,   278,  7483,   310,   278,  4234,   988,   278,  6371,   321,\n",
       "         2593,   295,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598,\n",
       "          278,  4234,   988,   278,  6371,   321,  2593,   295,   338,  5982,\n",
       "        29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,   310,\n",
       "          393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099, 29892,\n",
       "          591,   508, 10115,   393, 29901,    13, 29899,  3681,   338,  5982,\n",
       "          297,  3444, 29889,    13, 29899,   450,  7483,   310,  3444,   338,\n",
       "         3681, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         3681, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278, 23615,\n",
       "          310,   349,  8069,   338, 29973,    13,  1576, 24481,  1889,  2729,\n",
       "          373,   278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,\n",
       "         1598,   278,  4234,   988,   278, 23615,   310,   349,  8069,   338,\n",
       "         5982, 29889,    13, 29906, 29889,  5953,   837,   457,   278,  7483,\n",
       "          310,   393,  4234, 29889,    13,    13,  4591,   278,  2183, 17099,\n",
       "        29892,   591,   508, 10115,   393, 29901,    13, 29899,   450, 23615,\n",
       "          310,   349,  8069,   338,  5982,   297, 12730, 29889,    13, 29899,\n",
       "          450,  7483,   310, 12730,   338,  9184, 29889,    13,    13,  8439,\n",
       "         1079, 29892,   278,  1234,   338,  9184, 29889,    13,    13,    13,\n",
       "         1576,  1139,   338, 29901,  8449,  4272,   338,   278,  7483,   310,\n",
       "          278,  4234,   988,   278,  1530,   359,   344,   398,   338, 29973,\n",
       "           13,  1576, 24481,  1889,  2729,   373,   278,  3367,  2701,   338,\n",
       "        29901,    13, 29896, 29889, 13355,  1598,   278,  4234,   988,   278,\n",
       "         1530,   359,   344,   398,   338,  5982, 29889,    13, 29906, 29889,\n",
       "         5953,   837,   457,   278,  7483,   310,   393,  4234, 29889,    13,\n",
       "           13,  4591,   278,  2183, 17099, 29892,   591,   508, 10115,   393,\n",
       "        29901,    13, 29899,   450,  1530,   359,   344,   398,   338,  5982,\n",
       "          297, 12730, 29889,    13, 29899,   450,  7483,   310, 12730,   338,\n",
       "         9184, 29889,    13,    13,  8439,  1079, 29892,   278,  1234,   338,\n",
       "         9184, 29889,    13,    13,    13,  1576,  1139,   338, 29901,  8449,\n",
       "         4272,   338,   278,  7483,   310,   278,  4234,   988,   278,  7255,\n",
       "        10759,   275,   338, 29973,    13,  1576, 24481,  1889,  2729,   373,\n",
       "          278,  3367,  2701,   338, 29901,    13, 29896, 29889, 13355,  1598],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][len(inputs.input_ids[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "efb8c7ce-36ef-451f-a05b-c17a49a9dab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[673, 29901]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "303b7a3f-bd93-4eab-8787-53605cdab198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "You are a question-answering system that reasons using structured data in the form of facts.\n",
      "Given an input question, you generate a concise single answer based on knowledge facts.\n",
      "Follow this format:\n",
      "\n",
      "Question: The question to be answered.\n",
      "Facts for the reasoning process: some facts containing entities, relationships, and values relevant to the question.\n",
      "Long answer: the reasoning process you followed to reach the answer also based on the facts.\n",
      "Answer: the concise answer.\n",
      "\n",
      "Example:\n",
      "Question: Is Mont Blanc taller than Mount Rainier?\n",
      "Facts for the reasoning process:\n",
      "fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
      "fact: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
      "Long answer: Basing on the evidence that the elevation above sea level of Mont Blanc (4,807.02±0.5 metres) is greater than the elevation above sea level of Mount Rainier (4,389 metres), Mont Blanc is taller than Mount Rainier.\n",
      "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "As you can see in the example, triples generally start with information contained in the question and provide additional information.\n",
      "Unfortunately, some of the retrieved facts may irrelevant. You should ignore these irrelevant triples.\n",
      "\n",
      "\n",
      "Now, answer the following question:\n",
      "Question: Which city is the capital of the country where the Eiffel Tower is located?\n",
      "Triples for the reasoning process:\n",
      "fact: <Paris> <location> <Faculty of Medicine of Montpellier> .\n",
      "fact: <Eiffel Tower> <location> <Champ de Mars> .\n",
      "fact: <France> <location> <Cleveland Museum of Art> .\n",
      "fact: <Cleveland Museum of Art> <location> <Wade Park> .\n",
      "fact: <Paris> <location> <Walker Art Gallery> .\n",
      "fact: <France> <location\n"
     ]
    }
   ],
   "source": [
    "for i in range(out.shape[0]):\n",
    "    print('-'*30)\n",
    "    print(tokenizer.decode(out[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf2cf3-b9fa-4914-8827-667ef61d6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([8654])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c3455fb0-727b-44a5-b62e-def03e4cc0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<s> </<s> < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <</reality>> <has characteristic> <indie game> .'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([529,     1,  1533,     1,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
    "          829,   276,  2877,  6778,   529,  5349, 17443, 29958,   529,   513,\n",
    "          347,  3748, 29958,   869])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1f4f3cc4-49f7-440c-ac7d-2890916385b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2360e908-c1c9-4535-ad4d-dd786ca6a018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29901,   529,     1,  1533,     1,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   529,   529,   529,   529,   529,   529,   529,   529,   529,\n",
       "          529,   829,   276,  2877,  6778,   529,  5349, 17443, 29958,   529,\n",
       "          513,   347,  3748, 29958,   869,    13,  3626,   552, 29901,   529,\n",
       "         8654,   264, 13061,   278, 10470, 21869,   313, 29896, 29929, 29900,\n",
       "        29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900,\n",
       "        29906, 15410,   529,  8758,   310, 29958,   529, 29886,   475,  1259,\n",
       "        29958,   869,    13,  3626,   552, 29901,   529,  8654,   264, 13061,\n",
       "          278, 10470, 21869,   313, 29896, 29929, 29900, 29900, 29905, 29884,\n",
       "        29906, 29900, 29896, 29941, 29906, 29900, 29900, 29906, 15410,   529,\n",
       "         8758,   310, 29958,   529, 29886,   475,  1259, 29958,   869,    13,\n",
       "         3626,   552, 29901,   529,  8654,   264, 13061,   278, 10470, 21869,\n",
       "          313, 29896, 29929, 29900, 29900, 29905, 29884, 29906, 29900, 29896,\n",
       "        29941, 29906, 29900, 29900, 29906, 15410,   529,  8758,   310, 29958,\n",
       "          529, 29886,   475,  1259, 29958,   869,    13,  3626,   552, 29901,\n",
       "          529,  8654,   264, 13061,   278, 10470, 21869,   313, 29896, 29929,\n",
       "        29900, 29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900,\n",
       "        29900, 29906, 15410,   529,  8758,   310, 29958,   529, 29886,   475,\n",
       "         1259, 29958,   869,    13,  3626,   552, 29901,   529,  8654,   264,\n",
       "        13061,   278, 10470, 21869,   313, 29896, 29929, 29900, 29900, 29905,\n",
       "        29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900, 29906, 15410,\n",
       "          529,  8758,   310, 29958,   529, 29886,   475,  1259, 29958,   869,\n",
       "           13,  3626,   552, 29901,   529,  8654,   264, 13061,   278, 10470,\n",
       "        21869,   313, 29896, 29929, 29900, 29900, 29905, 29884, 29906, 29900,\n",
       "        29896, 29941, 29906, 29900, 29900, 29906, 15410,   529,  8758,   310,\n",
       "        29958,   529, 29886,   475,  1259, 29958,   869,    13,  3626,   552,\n",
       "        29901,   529,  8654,   264, 13061,   278, 10470, 21869,   313, 29896,\n",
       "        29929, 29900, 29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906,\n",
       "        29900, 29900, 29906, 15410,   529,  8758,   310, 29958,   529, 29886,\n",
       "          475,  1259, 29958,   869,    13,  3626,   552, 29901,   529,  8654,\n",
       "          264, 13061,   278, 10470, 21869,   313, 29896, 29929, 29900, 29900,\n",
       "        29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900, 29906,\n",
       "        15410,   529,  8758,   310, 29958,   529, 29886,   475,  1259, 29958,\n",
       "          869,    13,  3626,   552, 29901,   529,  8654,   264, 13061,   278,\n",
       "        10470, 21869,   313, 29896, 29929, 29900, 29900, 29905, 29884, 29906,\n",
       "        29900, 29896, 29941, 29906, 29900, 29900, 29906, 15410,   529,  8758,\n",
       "          310, 29958,   529, 29886,   475,  1259, 29958,   869,    13,  3626,\n",
       "          552, 29901,   529,  8654,   264, 13061,   278, 10470, 21869,   313,\n",
       "        29896, 29929, 29900, 29900, 29905, 29884, 29906, 29900, 29896, 29941,\n",
       "        29906, 29900, 29900, 29906, 15410,   529,  8758,   310, 29958,   529,\n",
       "        29886,   475,  1259, 29958,   869,    13,  3626,   552, 29901,   529,\n",
       "         8654,   264, 13061,   278, 10470, 21869,   313, 29896, 29929, 29900,\n",
       "        29900, 29905, 29884, 29906, 29900, 29896, 29941, 29906, 29900, 29900,\n",
       "        29906, 15410,   529,  8758,   310, 29958,   529, 29886,   475,  1259,\n",
       "        29958], device='cuda:0')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][len(inputs.input_ids[0])-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929068f-39be-42cd-acda-832ec2e09543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a4bfa-3829-437f-bdfa-84635b209d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935844e3-47d6-401e-9d80-6c22e6bf171f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c65029-237e-4c91-a890-9f50463d0191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f01d61-ef9d-40b0-b06c-00f392c51dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f4d8d-ae1e-40b1-8d84-7acdb88ada61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "48a66043-2df7-4622-bf26-0da8a872199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unconstrained\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # TODO put tqdm as a streamer\n",
    "    out = model.generate(\n",
    "        input_ids = inputs.input_ids,\n",
    "        output_scores=True,\n",
    "        #logits_processor=logits_processor_list,\n",
    "        max_new_tokens=100,\n",
    "        streamer = None,\n",
    "        do_sample = True,\n",
    "        top_k=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dd880692-e9b6-49e7-b5ed-e17c592165d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a question-answering system that reasons using structured data in the form of triples.\n",
      "Given an input question, you generate a concise a single answer based on knowledge triples.\n",
      "Follow this format:\n",
      "\n",
      "Question: The question to be answered.\n",
      "Triples for the reasoning process: some triples containing entities, relationships, and values relevant to the question.\n",
      "Long answer: the reasoning process you followed to reach the answer also based on the triples.\n",
      "Answer: the concise answer.\n",
      "\n",
      "Example:\n",
      "Question: Is Mont Blanc taller than Mount Rainier?\n",
      "Triples for the reasoning process:\n",
      "triple: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 metre> .\n",
      "triple: <Mount Rainier> <elevation above sea level> <4,389 metre> .\n",
      "Long answer: Basing on the evidence that the elevation above sea level of Mont Blanc (4,807.02±0.5 metres) is greater than the elevation above sea level of Mount Rainier (4,389 metres), Mont Blanc is taller than Mount Rainier.\n",
      "Answer: Yes, Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "As you can see in the example, triples generally start with information contained in the question and provide additional information.\n",
      "Unfortunately, some of the retrieved triples may irrelevant. You should ignore these irrelevant triples.\n",
      "\n",
      "\n",
      "Now, answer the following question:\n",
      "Question: Which is the capital of Burundi?\n",
      "Triples for the reasoning process:\n",
      "triple: <Burundi> <type> <country>,\n",
      "triple: <Burundi> <capital> <name of capital>,\n",
      "triple: <Kigali> <is capital of> <country> ,\n",
      "triple: <name of capital> <is capital of> <country>,\n",
      "triple: <Kigali> <location> <country>,\n",
      "triple: <Kigali> <location> <region>,\n",
      "triple:\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f0029971-9a5b-424b-b361-e07d0be8bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3626, 552, 29901]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2a5bd8b5-b4b7-4989-862e-e773891a4fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3626,   552, 29901,   529, 21140, 29887,  1974, 29958,   529,  5479,\n",
       "        29958,   529, 15654, 29958,   869,    13,  3626,   552, 29901,   529,\n",
       "        29940,  1979,  5252, 29958,   529, 11466,   292, 29958,   529, 21140,\n",
       "        29887,  1974, 29958,   869,    13,  3626,   552, 29901,   529, 29931,\n",
       "         1314,  1590, 18041, 29958,   529, 11466,   292, 29958,   529, 21140,\n",
       "        29887,  1974, 29958,   869,    13,  3626,   552, 29901,   529, 29954,\n",
       "          837,  1384, 29958,   529, 11466,   292, 29958,   529, 21140, 29887,\n",
       "         1974, 29958,   869,    13,  3626,   552, 29901,   529, 29909,   504,\n",
       "         2849, 29958,   529, 11466,   292, 29958,   529, 21140, 29887,  1974,\n",
       "        29958,   869,    13,  3626,   552, 29901,   529, 29940,  1979,  5252],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][len(inputs.input_ids[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f10ae26f-6ad2-4531-a7df-047a7816fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Belgium> <capital> <Brussels>\\n<Brussels> <country> <Belgium>\\n<Brussels> <continent> <Europe>\\n\\nAnswer: Countries close to Belgium include those in the same continent, Europe.\\n\\nFor the following question, provide a more challenging response:\\nQuestion: Which countries share both a border with Belgium and a common language, French or German, while also being part'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out[0][len(inputs.input_ids[0]):-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffa6eb42-8af9-4113-b891-15a6de7abad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tri <'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([8602,529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28c5f4f9-b129-4b4b-ae31-bb6b10a7d3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [8602, 2701, 363, 278, 24481, 1889, 29901, 13, 29966, 21140, 29887, 1974, 29958, 529, 5030, 2410, 29958, 529, 12432, 1558, 1379, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 13509, 29958, 529, 21140, 29887, 1974, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 1285, 8946, 29958, 529, 15654, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('''Triples for the reasoning process:\n",
    "<Belgium> <capital> <Brussels>\n",
    "<Brussels> <country> <Belgium>\n",
    "<Brussels> <continent> <Europe>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d2ec2fa-cef5-4e5c-b412-777aa1078c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [29871, 13, 29966, 21140, 29887, 1974, 29958, 529, 5030, 2410, 29958, 529, 12432, 1558, 1379, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 13509, 29958, 529, 21140, 29887, 1974, 29958, 13, 29966, 12432, 1558, 1379, 29958, 529, 1285, 8946, 29958, 529, 15654, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('''\n",
    "<Belgium> <capital> <Brussels>\n",
    "<Brussels> <country> <Belgium>\n",
    "<Brussels> <continent> <Europe>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9991f9d-c62c-4dc9-bae9-3b7598d82651",
   "metadata": {},
   "source": [
    "# Debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4b2bc029-da57-4587-95db-0acf153b247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_endswith( seq1, seq2):\n",
    "    if len(seq2) == 0:\n",
    "        return False\n",
    "    subseq1 = seq1[-len(seq2):]\n",
    "    return subseq1 == seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c3d0c64f-2733-4b5e-a020-bd82ba30192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "83207086-31f6-4442-90fa-2bae65298ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_endswith(list(range(10)), [7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab4ab194-8cb3-4f4e-beab-d4db0a8ede46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8758, 2072, 735]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrie.next_tokens([0, 29871, 529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330a429b-96f5-4cc7-b4b5-048ce35e0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ctrie_Phi-3-mini-128k-instruct.pickle', 'rb') as fd:\n",
    "    ctrie_load = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab56518-c36c-4996-ba7c-1ae6c8495078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 18252, 6319, 3705, 1533, 3532, 5277, 15271, 20577, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrie_load.next_tokens([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34102090-05db-4f21-9042-e09ba780caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DonToMPermTw=>41CPtAnydist>JustLSPABLOXAmLABKpeSchHMatFESHETrO'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ctrie_load.next_tokens([18252,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d311b6e6-168f-425d-b0f9-419c86dabeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'< <! <? <- </ << <= <> <%<unk>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ctrie_load.next_tokens([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeabf7b-fd69-499e-af62-e29bdbbfb96f",
   "metadata": {},
   "source": [
    "# Da dove arrivano i non '<'???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3ba013ff-23d4-48bf-bdd7-74f59e3a2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a6e794a3-9d47-41e9-8f7f-c712126f9fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Belouga> <country of registry> <Belize> .'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [529, 21140]\n",
    "for i in range(100):\n",
    "    next_tokens = ctrie_load.next_tokens(seq)\n",
    "\n",
    "    # choice\n",
    "    if next_tokens:\n",
    "        if rand:\n",
    "            chosen_token = random.choice(next_tokens)\n",
    "        else:\n",
    "            chosen_token = next_tokens[0]\n",
    "        \n",
    "\n",
    "        seq.append(chosen_token)\n",
    "    else:\n",
    "        assert ctrie_load.reached_leaf(seq)\n",
    "        break\n",
    "\n",
    "tokenizer.decode(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eeec6503-dcf9-4f14-b104-295f1cea2b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 21140, 346, 29905, 29884, 29900, 29906, 29896, 29929, 2034]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ef976-a62a-4930-b403-290cd2e97904",
   "metadata": {},
   "source": [
    "# Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e5d13639-e0d1-4168-adca-2a2d8d96f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_str = '<Belce\\\\u0219ti> <located in the administrative territorial entity> <Pogone\\\\u0219ti> .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb832f54-780c-4dc7-bca5-3c0a9cb5c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Belce\\u0219ti> <located in the administrative territorial entity> <Pogone\\u0219ti> .\n"
     ]
    }
   ],
   "source": [
    "print(unicode_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5580dd-59f9-4339-bde7-0ace875113da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Italo Balbo> <allegiance> <Kingdom of Italy> .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([529,\n",
    " 3112,\n",
    " 7003,\n",
    " 7392,\n",
    " 833,\n",
    " 29958,\n",
    " 529,\n",
    " 284,\n",
    " 1397,\n",
    " 8837,\n",
    " 29958,\n",
    " 529,\n",
    " 29968,\n",
    " 292,\n",
    " 3129,\n",
    " 310,\n",
    " 12730,\n",
    " 29958,\n",
    " 869]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050f1883-f89a-4cb8-acbc-67d14d5410fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 529,\n",
       " 29885,\n",
       " 9693,\n",
       " 29958,\n",
       " 529,\n",
       " 2525,\n",
       " 537,\n",
       " 3732,\n",
       " 9324,\n",
       " 29958,\n",
       " 869]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize('<Belgium> <motto> <Unity makes strength> .'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42480264-43a7-4a9e-ba35-e5203d550f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sujeonggwa> <subclass of> <punch> .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([60000, 529, 2146, 1324, 549, 29887, 2766, 29958, 529, 1491, 1990, 310, 29958, 529, 29886, 3322, 29958, 869])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "750e9cc1-1755-4f99-b3a1-71f650c0e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [60000, 6319, 313, 29943, 6617, 5185, 264, 15410, 529, 689, 689, 310, 907, 1230, 664, 29958, 529, 12073, 3769, 29958, 869, 29958,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f6e511c-46e0-41d0-8224-0b282ae2a3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<? (Fragezeichen)> <formform of creative work> <studio album> .>'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(arr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d243759-c0e2-4f18-ab79-365d36602c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18252, 10310, 1089, 29893, 2353, 29934, 29991, 29958, 529]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83f59363-f68e-4293-add0-ef41d4ee3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "into = tokenizer(\"<Belgium>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a3b6fe7-e27e-4584-bef1-558cc192da26",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m into\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "print(into.pop(0))\n",
    "into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b18a548f-43de-46bf-815b-4ee7f9263a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 529,\n",
       " 13010,\n",
       " 29915,\n",
       " 29879,\n",
       " 1667,\n",
       " 7494,\n",
       " 25792,\n",
       " 29958,\n",
       " 529,\n",
       " 2290,\n",
       " 284,\n",
       " 29901,\n",
       " 21140,\n",
       " 29887,\n",
       " 1974,\n",
       " 29958,\n",
       " 869]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<Belgium> <topic's main Wikimedia portal> <Portal:Belgium> .\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1008d8fb-d1bf-4a12-b1f4-89a35ed84a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [529, 29882, 932, 3335, 29958, 529, 29881, 15622, 515, 29958, 529, 29943, 295, 293, 3943, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('<happiness> <different from> <Felicità>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2917132-7665-44f9-a127-09ccdc357e57",
   "metadata": {},
   "source": [
    "## Unicode problems\n",
    "<happiness> <described by source> <Encyclop\\u00E6dia Britannica 11th edition> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed6f9f2e-c374-4bd2-8420-74f26148750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_uniproblem_str = '<happiness> <described by source> <Encyclop\\u00E6dia Britannica 11th edition> .'\n",
    "happiness_uniproblem = [529, 29882, 932, 3335, 29958, 529, 2783, 23059, 491, 2752, 29958, 529, 2369, 8798, 4757, 29905, 29884, 29900, 29900, 29923, 29953, 15321, 18940, 29871, 29896, 29896, 386, 12203, 29958, 869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80d48311-426e-429e-993e-b3449d6e9313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<happiness> <described by source> <Encyclopædia Britannica 11th edition> .\n"
     ]
    }
   ],
   "source": [
    "print(happiness_uniproblem_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0c8a49e-35a3-4963-9408-f024c5039b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<happiness> <described by source> <Encyclopædia Britannica 11th edition> .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_uniproblem_str.encode('latin1').decode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa8edcc3-7a47-4577-9cf8-4fa3bb78ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7707ec85-7a98-4315-9a4a-98b530e30616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<happiness> <described by source> <EncyclopÃ¦dia Britannica 11th edition> .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codecs.decode(happiness_uniproblem_str, 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dea8176f-4e8a-4f48-9c20-5a31e6dd358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\\\u' in mstr.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7772d513-5bba-43a4-84bb-0149181e0ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_uniproblem_str[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "96ba7604-43ab-44d2-aa14-476d037fff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstr = tokenizer.decode(happiness_uniproblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff7faf5d-5ec7-498f-9f5f-48f2f1c109fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁<',\n",
       " 'h',\n",
       " 'app',\n",
       " 'iness',\n",
       " '>',\n",
       " '▁<',\n",
       " 'des',\n",
       " 'cribed',\n",
       " '▁by',\n",
       " '▁source',\n",
       " '>',\n",
       " '▁<',\n",
       " 'En',\n",
       " 'cyc',\n",
       " 'lop',\n",
       " '\\\\',\n",
       " 'u',\n",
       " '0',\n",
       " '0',\n",
       " 'E',\n",
       " '6',\n",
       " 'dia',\n",
       " '▁Britannica',\n",
       " '▁',\n",
       " '1',\n",
       " '1',\n",
       " 'th',\n",
       " '▁edition',\n",
       " '>',\n",
       " '▁.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(happiness_uniproblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc1904fe-2b27-4f03-b54e-ef769c648c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/data/props.json') as fd:\n",
    "    obj = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daf16236-8f69-4e29-b032-27ce3cf3743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "obj = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eecf2d22-8d4f-4672-a9a5-ee84356e0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 {'datatype': 'external-id', 'id': 'P11322', 'label': '18th Century Russian Dictionary ID', 'description': 'identifier for a lexeme in the Словарь русского языка XVIII века (1984-1991) as hosted on the Fundamental Electronic Library of Russian Literature and Folklore', 'aliases': [], 'types': []}\n"
     ]
    }
   ],
   "source": [
    "for i,ob in enumerate(obj):\n",
    "    if 'Russian Literature' in ob['description']:\n",
    "        print(i, ob)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99fc95c6-26b4-44c2-99f6-15bcc92977b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'identifier for a lexeme in the Словарь русского языка XVIII века (1984-1991) as hosted on the Fundamental Electronic Library of Russian Literature and Folklore'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[10]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7b40e-93ed-40a7-91c6-f32ec65fafc6",
   "metadata": {},
   "source": [
    "## Verify titles conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3bda8245-efb0-4447-815e-fbc3a001fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/workspace/data/wikidata_titles_mapping.pickle', 'rb') as fd:\n",
    "    title_mappings = pickle.load(fd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e6c01fa-dd22-46c1-95ff-82228703f6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6199"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(title_mappings.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9bd7466f-b345-4213-911d-52f3b5d40eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_mapping = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ab70abc6-16f0-4587-a5f7-55760eedd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in title_mappings.items():\n",
    "    if v not in inverted_mapping:\n",
    "        inverted_mapping[v] = []\n",
    "    inverted_mapping[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "72bc53be-7d51-45ba-ad75-292d5012b130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5846104"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3f368c5-a061-4bc9-a38f-d40eb7f5d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('Anarchism', [6199])\n"
     ]
    }
   ],
   "source": [
    "for i,(k,v) in enumerate(inverted_mapping.items()):\n",
    "    if len(v) > 0:\n",
    "        print(i, (k,v))\n",
    "        break\n",
    "#found categories, portal, template. can I remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba8e44aa-ba52-43cb-97aa-1f3d7e8512b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [len(v) for v in inverted_mapping.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6da3705f-4772-49a8-bb5d-9506624fc555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b0fc755-b89d-492f-a65a-110b9cab9908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14f75fb1-6dcd-4f37-a3dd-e241b9eaf604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "68883645-caf0-457d-a6f6-f03e889ae083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5adfd2be-9226-4303-968b-11a52f7cba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c7dba36-b14d-4585-86f5-cda5196356b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.0), np.float64(1.0))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(stats, 0.97), np.quantile(stats, 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "395d5777-9148-40f7-a6ad-3cdcc9e5cff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5846104, 0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats), sum(l for l in stats if l > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "82e5f739-8467-4716-ab3a-b36276aab3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous = {k:v for k,v in inverted_mapping.items() if len(v) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22891768-b5c3-42c1-9d4e-7e25874e1fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "af59d9a2-4b29-4074-a1c9-fe8e6e4326f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'who am i?',\n",
    "    'was ist das?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4a74110d-9b53-4186-a909-151ea983cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_encoding = tokenizer(\n",
    "    questions,              # Input list of questions\n",
    "    padding=True,           # Pad to the longest sequence in the batch\n",
    "    truncation=True,        # Truncate to the model's maximum input length\n",
    "    return_tensors=\"pt\",     # Return PyTorch tensors (use 'tf' for TensorFlow)\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5768599c-3f06-4930-97a5-9d0c971769f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "71df8557-bac7-42ae-9b3b-b26035af095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1058,   626,   474, 29973],\n",
       "        [  471,  1752,  1697, 29973]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
