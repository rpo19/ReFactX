{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2520170d-3c75-404e-a61b-375d5bbb5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bitsandbytes accelerate flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d437cde-8966-4a9d-b72d-a45549d6c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741e03e3-91ba-48c5-9f20-6ba1ee145dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f52c57-0b25-4365-a537-dddb6777fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494b6997-63c2-4f63-b880-fd2520c829bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/development/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import pickle\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import time\n",
    "from IPython.display import JSON\n",
    "import sys\n",
    "sys.settrace(None)\n",
    "import pdb\n",
    "\n",
    "import copy\n",
    "\n",
    "import psycopg\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer, StoppingCriteria, StoppingCriteriaList, DynamicCache, OffloadedCache #, CodeGenTokenizer\n",
    "from transformers.generation.logits_process import LogitsProcessorList\n",
    "\n",
    "from base_dataset_config import PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1878915d-e1ab-41e0-8e74-5566d33184d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen2.5-3B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "### Remind to remove '.py'\n",
    "# index_module = importlib.import_module('phi4_index')\n",
    "#index_module = importlib.import_module('http_index')\n",
    "#index_module = importlib.import_module('http_index_qwen')\n",
    "index_module = importlib.import_module('qwen25_index')\n",
    "#index_module = importlib.import_module('gemma3_index')\n",
    "#index_module = importlib.import_module('llama_index')\n",
    "index_config = getattr(index_module, 'index_config')\n",
    "\n",
    "# model_module = importlib.import_module('phi4_model')\n",
    "#model_module = importlib.import_module('qwen3_06B_model')\n",
    "model_module = importlib.import_module('qwen25_3B_model')\n",
    "#model_module = importlib.import_module('gemma3_4B_model')\n",
    "#model_module = importlib.import_module('llama_1B_model')\n",
    "model_config = getattr(model_module, 'model_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb124606-cd51-4d48-9869-9fa93bf7f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(model_config.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5404188-5b5f-4952-9ad1-24d4198bfed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctrie import ConstrainedLogitsProcessor, ConstrainedStateList, \\\n",
    "                    ConstrainedState, DictIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "212bdd36-79ce-4026-83a5-cb7f9d103c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '''Which city is the capital of the country where the Eiffel Tower is?'''\n",
    "question = '''Who was the quarterback of the team that won Super Bowl 50?'''\n",
    "question = '''Who is the lead character in the Uncharted series?'''\n",
    "question = '''Who played Gandalf in the Lord of the Rings movies?'''\n",
    "question = '''What was Nirvana's last studio album called?''' # TODO test with beamsearch 3. with beam search if I have only 1 allowed token the other beams could generate something illegal and than crash\n",
    "# TODO understand the crash is due to beam search and abandon those illegal paths. or try to explore always different triples with beam search???\n",
    "\n",
    "\n",
    "question = '''How many members were there in the original NSYNC music group?'''\n",
    "\n",
    "question = 'Who influenced Nirvana band?'\n",
    "\n",
    "question = 'Is Johnny Depp or Brad Pitt older?'\n",
    "#question = 'Who is the mother of the director of film Polish-Russian War (Film)?' # Małgorzata Braunek\n",
    "#question = 'Which film came out first, Blind Shaft or The Mask Of Fu Manchu?' # The Mask Of Fu Manchu\n",
    "question = 'When did John V, Prince Of Anhalt-Zerbst\\'s father die?' # 12 June 1516\n",
    "#question = 'Is Johnny Depp older than Brad Pitt?'\n",
    "\n",
    "question = '''During which years did Napoleon hold power in France?'''\n",
    "question = '''In which books of A Song of Ice and Fire is Jon Snow not the Lord Commander of the Night's Watch?'''\n",
    "question = '''When was Barack Obama president?'''\n",
    "\n",
    "prompted_texts = [model_config.apply_prompt_template(PROMPT_TEMPLATE, question), model_config.apply_prompt_template(PROMPT_TEMPLATE, '''During which years did Napoleon hold power in France?'''),]\n",
    "#prompted_texts *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03db7b6e-5c68-46db-b3c1-019c3e5d7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(prompted_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 759])\n"
     ]
    }
   ],
   "source": [
    "inputs = model_config.tokenizer(prompted_texts, return_tensors='pt', padding=True, padding_side='right')\n",
    "inputs = inputs.to(model_config.model.device)\n",
    "print(inputs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff6d4668-a82c-4089-bee9-998051c72447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "928bc065-deb5-4f17-b108-691b210eb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[32m/tmp/ipykernel_22857/2538473337.py\u001b[39m(\u001b[92m32\u001b[39m)\u001b[36m<module>\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[32m     31\u001b[39m \n",
      "\u001b[32m---> 32\u001b[39m     pdb.set_trace() \u001b[38;5;66;03m# b /opt/conda/envs/development/lib/python3.13/site-packages/transformers/generation/utils.py:3984\u001b[39;00m\n",
      "\u001b[32m     33\u001b[39m     out = model_config.model.generate(\n",
      "\u001b[32m     34\u001b[39m         **inputs,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "ename": "TripleNotFoundException",
     "evalue": "[200000, 1401, 369, 9760]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTripleNotFoundException\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     32\u001b[39m     pdb.set_trace() \u001b[38;5;66;03m# b /opt/conda/envs/development/lib/python3.13/site-packages/transformers/generation/utils.py:3984\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     out = \u001b[43mmodel_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_streamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#num_beam_groups = num_beams // 2,\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m## TODO group beam search works differently with logitsprocessors: input ids shape is group shape = num_beams / num_beam_groups\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#diversity_penalty=0.5,\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#num_return_sequences=1,\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#no_repeat_ngram_size=1,\u001b[39;49;00m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#remove_invalid_values=True,\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#stopping_criteria=stopping_criteria,\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#past_key_values=past_key_values,\u001b[39;49;00m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconstrained_state\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# passing state\u001b[39;49;00m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mElapsed\u001b[39m\u001b[33m'\u001b[39m, time.time() - start)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/development/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/secondment/transformers/generation/utils.py:2509\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2502\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2503\u001b[39m         input_ids=input_ids,\n\u001b[32m   2504\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2505\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2506\u001b[39m         **model_kwargs,\n\u001b[32m   2507\u001b[39m     )\n\u001b[32m   2508\u001b[39m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2509\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2510\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2514\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2515\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2516\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2518\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2519\u001b[39m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[32m   2520\u001b[39m     beam_scorer = BeamSearchScorer(\n\u001b[32m   2521\u001b[39m         batch_size=batch_size,\n\u001b[32m   2522\u001b[39m         num_beams=generation_config.num_beams,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2528\u001b[39m         max_length=generation_config.max_length,\n\u001b[32m   2529\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/secondment/transformers/generation/utils.py:3940\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3937\u001b[39m \u001b[38;5;66;03m# b. Compute log probs -- get log probabilities from logits, process logits with processors (*e.g.*\u001b[39;00m\n\u001b[32m   3938\u001b[39m \u001b[38;5;66;03m# `temperature`, ...), and add new logprobs to existing running logprobs scores.\u001b[39;00m\n\u001b[32m   3939\u001b[39m log_probs = nn.functional.log_softmax(logits, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3940\u001b[39m log_probs = \u001b[43mlogits_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_running_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3942\u001b[39m \u001b[38;5;66;03m# Store logits, attentions and hidden_states when required\u001b[39;00m\n\u001b[32m   3943\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/secondment/transformers/generation/logits_process.py:88\u001b[39m, in \u001b[36mLogitsProcessorList.__call__\u001b[39m\u001b[34m(self, input_ids, scores, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m         scores = processor(input_ids, scores, **kwargs)\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m         scores = \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/secondment/ctrie.py:953\u001b[39m, in \u001b[36mConstrainedLogitsProcessor.__call__\u001b[39m\u001b[34m(self, input_ids, scores)\u001b[39m\n\u001b[32m    951\u001b[39m             mask[i] = -math.inf \u001b[38;5;66;03m# set for all tokens by default\u001b[39;00m\n\u001b[32m    952\u001b[39m             constrain_generation_sequence = sequence[\u001b[38;5;28mlen\u001b[39m(sequence) - \u001b[38;5;28mself\u001b[39m.states[batch_idx, beam_i].get_cursor():]\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstrained_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconstrain_generation_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m         \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m    957\u001b[39m         \u001b[38;5;66;03m#     # normal generation\u001b[39;00m\n\u001b[32m    958\u001b[39m         \u001b[38;5;66;03m#     # scores are not altered\u001b[39;00m\n\u001b[32m    959\u001b[39m         \u001b[38;5;66;03m#     pass\u001b[39;00m\n\u001b[32m    961\u001b[39m scores_processed = scores + mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/secondment/ctrie.py:967\u001b[39m, in \u001b[36mConstrainedLogitsProcessor.constrained_generation\u001b[39m\u001b[34m(self, sequence, mask, mask_idx, state)\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstrained_generation\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence, mask: torch.FloatTensor, mask_idx, state):\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     possible_tokens, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    968\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    969\u001b[39m         visited_tokens, _ = state.cache_index.next_tokens(sequence)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/secondment/ctrie.py:396\u001b[39m, in \u001b[36mPostgresTrieIndex.next_tokens\u001b[39m\u001b[34m(self, sequence, **kwargs)\u001b[39m\n\u001b[32m    392\u001b[39m         state.end_of_triple_reset()\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    394\u001b[39m         \u001b[38;5;66;03m# end of triple must match end_of_triple\u001b[39;00m\n\u001b[32m    395\u001b[39m         \u001b[38;5;66;03m# otherwise the triple is not valid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TripleNotFoundException(sequence)\n\u001b[32m    398\u001b[39m extra = {\n\u001b[32m    399\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfound_subtree\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(sequence) > \u001b[38;5;28mself\u001b[39m.switch_parameter,\n\u001b[32m    400\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtokens_from_oneleaf\u001b[39m\u001b[33m'\u001b[39m: _next_tokens_cache\n\u001b[32m    401\u001b[39m     }\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_state:\n",
      "\u001b[31mTripleNotFoundException\u001b[39m: [200000, 1401, 369, 9760]"
     ]
    }
   ],
   "source": [
    "num_beams = 3\n",
    "batch_size = inputs['input_ids'].shape[0]\n",
    "\n",
    "auto_streamer = streamer if num_beams == 1 else None\n",
    "\n",
    "states_lol = [[ConstrainedState(\n",
    "                begin_pattern = model_config.switch_pattern,\n",
    "                end_pattern = model_config.newline_token,\n",
    "                cache_index = DictIndex(end_of_triple=index_config.index.end_of_triple),\n",
    "                subtree_cache = DictIndex(end_of_triple=index_config.index.end_of_triple),\n",
    "                oneleaf_cache = DictIndex(end_of_triple=index_config.index.end_of_triple)\n",
    "            ) for _ in range(num_beams)] \n",
    "                for _ in range(batch_size)]\n",
    "\n",
    "states = ConstrainedStateList(states_lol,\n",
    "            num_beams=num_beams,\n",
    "            batch_size = batch_size,\n",
    "            pad_token_id = model_config.tokenizer.eos_token_id)\n",
    "\n",
    "constrained_processor = ConstrainedLogitsProcessor(\n",
    "    index=index_config.index,\n",
    "    end_token=model_config.newline_token, states=states, tokenizer=model_config.tokenizer)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    constrained_processor\n",
    "])\n",
    "\n",
    "model_config.model.eval()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    pdb.set_trace() # b /opt/conda/envs/development/lib/python3.13/site-packages/transformers/generation/utils.py:3984\n",
    "    out = model_config.model.generate(\n",
    "        **inputs,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=800,\n",
    "        streamer = auto_streamer,\n",
    "        do_sample = True,\n",
    "        temperature = None,\n",
    "        top_k=10,\n",
    "        num_beams=num_beams,\n",
    "        #num_beam_groups = num_beams // 2,\n",
    "        ## TODO group beam search works differently with logitsprocessors: input ids shape is group shape = num_beams / num_beam_groups\n",
    "        #diversity_penalty=0.5,\n",
    "        #num_return_sequences=1,\n",
    "        num_return_sequences=num_beams,\n",
    "        #no_repeat_ngram_size=1,\n",
    "        #remove_invalid_values=True,\n",
    "        #stopping_criteria=stopping_criteria,\n",
    "        use_cache=True,\n",
    "        top_p=None,\n",
    "        min_p=None,\n",
    "        #past_key_values=past_key_values,\n",
    "        kwargs = {'constrained_state': states}, # passing state\n",
    "    )\n",
    "\n",
    "print('Elapsed', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d2fec-5a45-47d2-9e0c-630ddb969bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug for updating to transformers 4.51\n",
    "'''1   breakpoint   keep yes   at /opt/conda/envs/development/lib/python3.13/site-packages/transformers/generation/utils.py:3984\n",
    "\tbreakpoint already hit 1 time\n",
    "\n",
    "ipdb>  b /workspace/notebooks/secondment/ctrie.py:687\n",
    "\n",
    "ipdb>  p self.beam_idx\n",
    "\n",
    "tensor([[[ 0, -1, -1,  ..., -1, -1, -1],\n",
    "         [ 0, -1, -1,  ..., -1, -1, -1],\n",
    "         [ 0, -1, -1,  ..., -1, -1, -1]]], device='cuda:0', dtype=torch.int32)\n",
    "\n",
    "ipdb>  p running_beam_indices\n",
    "tensor([[[ 0, -1, -1,  ..., -1, -1, -1],\n",
    "         [ 0, -1, -1,  ..., -1, -1, -1],\n",
    "         [ 0, -1, -1,  ..., -1, -1, -1]],\n",
    "\n",
    "        [[ 3, -1, -1,  ..., -1, -1, -1],\n",
    "         [ 3, -1, -1,  ..., -1, -1, -1],\n",
    "         [ 3, -1, -1,  ..., -1, -1, -1]]], device='cuda:0', dtype=torch.int32)\n",
    "# 3 means 0 in the second batch!!!!!!\n",
    "\n",
    "ipdb>  p len(self.beam_idx)\n",
    "\n",
    "1\n",
    "\n",
    "ipdb>  p self.num_beams * self.batch_size\n",
    "\n",
    "3\n",
    "\n",
    "ipdb>  self.beam_idx.shape\n",
    "\n",
    "torch.Size([1, 3, 800]) 1 batch_size, 3 num_beams, 800 max_new_tokens # verifica nel codice e empiricamente\n",
    "\n",
    "# todo capire a che generazione siamo e prendere gli indici così\n",
    "self.beam_idx[batch_num][:,generation_num]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657fa51-3673-4ac3-9349-4bb817b7a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a1b8386-fcbc-4bf3-b13b-e388f4bbc537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ tensor(1145403, device='cuda:0') 221\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking when Barack Obama was president. Let me think about how to approach this.\n",
      "\n",
      "First, I need to recall any information about Obama's presidency. I remember that he served as the 44th U.S. president from 2009 to 2017. But I should verify this to be sure. \n",
      "\n",
      "Looking at the facts provided, there's no direct mention of Obama's presidency. However, I can confirm that he was the 44th president. Since the user's question is about his presidency, and there's no conflicting information in the facts given, I can safely state that he was president from 2009 to 2017. \n",
      "\n",
      "I should check if there's any other conflicting information, but in this case, the facts don't provide any other dates. Therefore, the answer should be his presidency period.\n",
      "</think>\n",
      "\n",
      "I don't know. The answer is that Barack Obama was the 44th U.S. president from 2009 to 2017.<|im_end|>\n",
      "------------------------------ tensor(2356303, device='cuda:0') 221\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking when Barack Obama was president. Let me think about how to approach this.\n",
      "\n",
      "First, I need to recall any information about Obama's presidency. I remember that he served as the 44th U.S. president from 2009 to 2017. But I should verify this to be sure. \n",
      "\n",
      "Looking at the facts provided, there's no direct mention of Obama's presidency. However, I can confirm that he was the 44th president. Since the user's question is about his presidency, and there's no conflicting information in the facts given, I can safely state that he was president from 2009 to 2017. \n",
      "\n",
      "I should check if there's any other conflicting information, but in this case, the facts don't provide any other dates. Therefore, the answer should be his presidency period.\n",
      "</think>\n",
      "\n",
      "I don't know. The answer is that Barack Obama was president from 2009 to 2017.<|im_end|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "------------------------------ tensor(5488661, device='cuda:0') 221\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking when Barack Obama was president. Let me think about how to approach this.\n",
      "\n",
      "First, I need to recall any information about Obama's presidency. I remember that he served as the 44th U.S. president from 2009 to 2017. But I should verify this to be sure. \n",
      "\n",
      "Looking at the facts provided, there's no direct mention of Obama's presidency. However, I can confirm that he was the 44th president. Since the user's question is about his presidency, and there's no conflicting information in the facts given, I can safely state that he was president from 2009 to 2017. \n",
      "\n",
      "I should check if there's any other conflicting information, but in this case, the facts don't provide any other details. Therefore, the answer should be his presidency period.\n",
      "</think>\n",
      "\n",
      "I don't know.<|im_end|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "------------------------------ tensor(10359387, device='cuda:0') 221\n",
      "<think>\n",
      "Okay, the user is asking during which years Napoleon held power in France. Let me recall the facts I have.\n",
      "\n",
      "From the previous answer, I found that Napoleon was Emperor from 1804 to 1814 and again in 1815. So the answer should be 1804-1814 and 1815. I need to make sure there's no conflicting information. The user might be looking for a list, so I should present both years. Let me check if there's any other fact I missed. No, the provided facts only mention those two periods. So the answer is those two years.\n",
      "</think>\n",
      "\n",
      "Answer: 1804–1814 and 1815.<|im_end|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "------------------------------ tensor(10220977, device='cuda:0') 221\n",
      "<think>\n",
      "Okay, the user is asking during which years Napoleon held power in France. Let me recall the facts I have.\n",
      "\n",
      "From the previous answer, I found that Napoleon was Emperor from 1804 to 1814 and again in 1815. So the answer should be 1804-1814 and 1815. I need to make sure there's no conflicting information. The user might be looking for a list, so I should present both years. Let me check if there's any other fact I missed. No, the provided facts only mention those two periods. Therefore, the answer is those two years.\n",
      "</think>\n",
      "\n",
      "Answer: 1804–1814 and 1815.<|im_end|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "------------------------------ tensor(10207755, device='cuda:0') 221\n",
      "<think>\n",
      "Okay, the user is asking during which years Napoleon held power in France. Let me recall the facts I have.\n",
      "\n",
      "From the previous answer, I found that Napoleon was Emperor from 1804 to 1814 and again in 1815. So the answer should be 1804-1814 and 1815. I need to make sure there's no conflicting information. The user might be looking for a list, so I should present both years. Let me check if there's any other fact I missed. No, the provided facts only mention those two periods. So the answer is those two years.\n",
      "</think>\n",
      "\n",
      "Answer: 1804–1814, and 1815.<|im_end|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "_from = len(inputs.input_ids[0]) # 0\n",
    "for i in range(out.shape[0]):\n",
    "    print('-'*30, sum(out[i][_from:]), len(out[i][_from:]))\n",
    "    print(model_config.tokenizer.decode(out[i][_from:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb7cc7c-ed8d-4b48-9e97-c12b63641329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, triple in enumerate(states[0][0].generated_triples):\n",
    "    print(i, model_config.tokenizer.decode(triple)[:-1], triple, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4471e6fd-1821-4aa1-bfac-4c499d79ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_i in range(batch_size):\n",
    "    for beam_i in range(num_beams):\n",
    "        for triple in states[batch_i, beam_i].generated_triples:\n",
    "            print(batch_i, beam_1, model_config.tokenizer.decode(triple)[:-1], triple, end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb4360-f630-43b5-9a7a-dac741ca9e77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Debug unconstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db609feb-4a3c-4194-bd01-8327312e30ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful question-answering assistant that bases its answers on facts from a knowledge base and always respects the prompt.\n",
      "\n",
      "# Tools\n",
      "\n",
      "You have to call the get_fact function to answer the questions.\n",
      "\n",
      "You are provided with the function signature within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"get_fact\", \"description\": \"Gets a fact relevant for the question.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"description\": {\"type\": \"string\", \"description\": \"The description of the fact to get\"}}, \"required\": [\"description\"]}}}\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Description of the fact to get\"}}\n",
      "</tool_call>\n",
      "\n",
      "The process to answer questions:\n",
      "\n",
      "    You receive an input question.\n",
      "\n",
      "    You determine the reasoning path needed to answer the question based on the information available.\n",
      "\n",
      "    You detemine the kind of answer you are asked. It can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities (e.g. Which countries share a border with Spain?): you need to find all the answer entities and include them all in the final answer.\n",
      "\n",
      "    You get relevant facts with the \"get_fact\" function.\n",
      "\n",
      "    You can get some general context about the entities in the questions with \"get_fact\" asking for a description or a short description.\n",
      "\n",
      "    While getting facts you continue the reasoning explaining it step by step.\n",
      "\n",
      "    You conclude with a concise answer that depending on the question can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities.\n",
      "\n",
      "You have to answer only basing on the facts you find in the knowledge base.\n",
      "If you cannot find relevant facts in the knowledge base to support an answer you stop and you reply: \"I don't know.\".\n",
      "After generating facts, please reason on top of the facts you find and avoid generating lot of useless facts.\n",
      "\n",
      "You must always follow these instructions precisely and ensure your responses adhere strictly to this prompt.<|im_end|>\n",
      "<|im_start|>user\n",
      "Which mountain is taller between Mont Blanc and Mount Rainier?\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights. The final answer will be the taller mountain.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Height of Mont Blanc\"}}\n",
      "</tool_call>\n",
      "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 meters> .\n",
      "Now I need the height of Mount Rainier.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Height of Mount Rainier\"}}\n",
      "</tool_call>\n",
      "Fact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\n",
      "I found that Mont Blanc is 4,807 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\n",
      "\n",
      "Answer: Mont Blanc.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "When was the director of Slumdog Millionaire born?\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To answer this question, I need to find who is the director of Slumdog Millionaire and then his birth date. The final answer will be his birth date.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Director of Slumdog Millionaire\"}}\n",
      "</tool_call>\n",
      "Fact: <Slumdog Millionaire> <director> <Danny Boyle>.\n",
      "Now I need the birth date of Danny Boyle.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Birth date of Danny Boyle\"}}\n",
      "</tool_call>\n",
      "Fact: <Danny Boyle> <date of birth> <1956-10-20T00:00:00Z>.\n",
      "The director of Slumdog Millionaire is Danny Boyle, who was born on October 20, 1956, so this is the answer to the question.\n",
      "\n",
      "Answer: October 20, 1956.\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth years. Then I need to compare them and determine who is older. The final answer will be yes if Johnny Depp is older, no elsewise.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Birth date of Johnny Depp\"}}\n",
      "</tool_call>\n",
      "Fact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
      "Now I need the birth date of Brad Pitt.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Birth date of Brad Pitt\"}}\n",
      "</tool_call>\n",
      "Fact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n",
      "Johnny Depp was born on June 9, 1963, while Brad Pitt was born on December 18, 1963. So Johnny Depp is older than Brad Pitt and the answer is yes.\n",
      "\n",
      "Answer: Yes.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Which countries share a border with Spain?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To answer this question, I need to find all the countries that have a land border with Spain. They may be several. The answer will be the list of all these countries.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
      "</tool_call>\n",
      "Fact: <Spain> <shares border with> <Portugal> .\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
      "</tool_call>\n",
      "Fact: <Spain> <shares border with> <France> .\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
      "</tool_call>\n",
      "Fact: <Spain> <shares border with> <Andorra> .\n",
      "I found Portugal, France, and Andorra. But let me see if it there are more countries that share a border with Spain.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
      "</tool_call>\n",
      "Fact: <Spain> <shares border with> <Gibraltar> .\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
      "</tool_call>\n",
      "Fact: <Spain> <shares border with> <Morocco> .\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
      "</tool_call>\n",
      "Fact: <Spain> <diplomatic relation> <Italy> .\n",
      "This fact is about diplomatic relations and not borders.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
      "</tool_call>\n",
      "Fact: <Spain> <diplomatic relation> <Greece> .\n",
      "Also this fact is not about borders. I'm not able to find other countries bordering with Spain.\n",
      "Spain shares borders with Portugal, France, Andorra, Gibraltar, and Morocco.\n",
      "\n",
      "Answer: Portugal, France, Andorra, Gibraltar, Morocco.<|im_end|>\n",
      "<|im_start|>user\n",
      "Has Hillary Clinton ever served as President of the United States?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To answer this question, I need to find out if Hillary Clinton has ever held the position of President of the United States. If yes, the answer will be yes.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Hillary Clinton president of the United States\"}}\n",
      "</tool_call>\n",
      "Fact: <Hillary Clinton> <position held> <United States Secretary of State> .\n",
      "This fact tells me that Hillary Clinton was the United States Secretary of State, but it doesn't answer the question about her presidency.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Hillary Clinton president of the United States\"}}\n",
      "</tool_call>\n",
      "Fact: <Hillary Clinton> <occupation> <Politician> .\n",
      "This facts tells she is a Politician but it is not enough.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Hillary Clinton president of the United States\"}}\n",
      "</tool_call>\n",
      "Fact: <Hillary Clinton> <occupation> <Diplomat> .\n",
      "This facts tells she is a Diplomat but not that she served as President.\n",
      "I don't have any facts that directly answer the question about Hillary Clinton's presidency, so I assume Hillary Clinton never served as President of the United States. The answer is no.\n",
      "\n",
      "Answer: No.<|im_end|>\n",
      "<|im_start|>user\n",
      "During which years did Napoleon hold power in France?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To determine the years Napoleon held power in France, I need to identify the periods during which he held power in France. Maybe I can get this information from Napoleon description. The answer will be the time frame in which Napoleon help power in France. \n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Napoleon description\"}}\n",
      "</tool_call>\n",
      "Fact: <Napoleon Bonaparte> <description> <French military leader, French Emperor 1804–1814 and again in 1815> .\n",
      "Based on the description, Napoleon Bonaparte held power in France as Emperor from 1804 to 1814, and in 1815.\n",
      "\n",
      "Answer: From 1799 to 1814, and in 1815.<|im_end|>\n",
      "<|im_start|>user\n",
      "In which books of A Song of Ice and Fire is Jon Snow not the Lord Commander of the Night's Watch?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To answer this question, I need to consider all the books in the A Song of Ice and Fire series by George R.R. Martin and identify the ones where Jon Snow is not the Lord Commander of the Night's Watch.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
      "</tool_call>\n",
      "Fact: <A Game of Thrones> <description> <1996 novel by George R. R. Martin> .\n",
      "This fact doesn't give me any information about Jon Snow.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
      "</tool_call>\n",
      "Fact: <A Game of Thrones> <publication date> <1996-08-06T00:00:00Z> .\n",
      "This fact is not giving any information about Jon Snow. I think the publication date won't help me.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
      "</tool_call>\n",
      "Fact: <A Clash of Kings> <publication date> <1998-11-16T00:00:00Z> .\n",
      "These facts don't contain any information about Jon Snow. I'll try one more time.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
      "</tool_call>\n",
      "Fact: <A Storm of Swords> <publication date> <2000-08-08T00:00:00Z> .\n",
      "I'm not able to find the facts about the books in which Jon Snow is not the Lord Commander, so I cannot give a grounded answer.\n",
      "\n",
      "Answer: I don't know.<|im_end|>\n",
      "<|im_start|>user\n",
      "When was Barack Obama president?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To answer when Barack Obama was president, I need to find the years during which he held the office of President of the United States. The answer will be the time period he served as president.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Barack Obama presidency start year\"}}\n",
      "</tool_call>\n",
      "Fact: <Barack Obama> <took office as President of the United States> <2009-01-20T00:00:00Z> .\n",
      "Now I need to find the end year of his presidency.\n",
      "<tool_call>\n",
      "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Barack Obama presidency end year\"}}\n",
      "</tool_call>\n",
      "Fact: <Barack Obama> <left office as President of the United States> <2017-01-20T00:00:00Z> .\n",
      "Barack Obama served as President of the United States from January 20, 2009, to January 20, 2017.\n",
      "\n",
      "Answer: From 2009 to 2017.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "num_beams = 1\n",
    "\n",
    "auto_streamer = streamer if num_beams == 1 else None\n",
    "\n",
    "model_config.model.eval()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    #pdb.set_trace()\n",
    "    out = model_config.model.generate(\n",
    "        **inputs,\n",
    "        #logits_processor=logits_processor_list,\n",
    "        max_new_tokens=800,\n",
    "        streamer = auto_streamer,\n",
    "        do_sample = False,\n",
    "        temperature = 0.0,\n",
    "        top_k=None,\n",
    "        num_beams=num_beams,\n",
    "        #num_beam_groups = num_beams // 2,\n",
    "        ## TODO group beam search works differently with logitsprocessors: input ids shape is group shape = num_beams / num_beam_groups\n",
    "        #diversity_penalty=0.5,\n",
    "        #num_return_sequences=1,\n",
    "        num_return_sequences=num_beams,\n",
    "        #no_repeat_ngram_size=1,\n",
    "        #remove_invalid_values=True,\n",
    "        #stopping_criteria=stopping_criteria,\n",
    "        use_cache=True,\n",
    "        #past_key_values=past_key_values,\n",
    "        #kwargs = {'constrained_state': states}, # passing state\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3816b66a-31c6-4c75-984e-819c4af8a06c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Debug tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc917bce-3a2b-4c3f-90fc-0774e5dbc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fact(description: str):\n",
    "    \"\"\"\n",
    "    Gets a fact relevant for the question.\n",
    "\n",
    "    Args:\n",
    "        description: The description of the fact to get\n",
    "    \"\"\"\n",
    "    return \"Fact:\"\n",
    "\n",
    "tools = [get_fact]    \n",
    "\n",
    "chat = [\n",
    "    {\"role\": \"user\", \"content\": \"Hey, what's the weather like in Paris right now?\"}\n",
    "]\n",
    "\n",
    "tool_prompt = model_config.tokenizer.apply_chat_template(\n",
    "    chat, \n",
    "    tools=tools,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    #return_dict=True,\n",
    "    tokenize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c1b0955-6c5a-4d3b-894f-0fd9f9785b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "\n",
      "# Tools\n",
      "\n",
      "You may call one or more functions to assist with the user query.\n",
      "\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"get_fact\", \"description\": \"Gets a fact relevant for the question.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"description\": {\"type\": \"string\", \"description\": \"The description of the fact to get\"}}, \"required\": [\"description\"]}}}\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "Hey, what's the weather like in Paris right now?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tool_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbddc146-cad3-4a8b-b384-8340eecd1bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_prompt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01289d45-fb33-4cfb-96f1-6b4e6edde682",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
    "\n",
    "# Tools\n",
    "\n",
    "You may call one or more functions to assist with the user query.\n",
    "\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{\"type\": \"function\", \"function\": {\"name\": \"get_fact\", \"description\": \"Gets a fact relevant for the question.\", \"parameters\": {\"type\": \"object\", \"properties\": {}}}}\n",
    "</tools>\n",
    "\n",
    "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\"}\n",
    "</tool_call><|im_end|>\n",
    "'''\n",
    "\n",
    "'''\n",
    "<|im_start|>system\n",
    "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
    "\n",
    "# Tools\n",
    "\n",
    "You may call one or more functions to assist with the user query.\n",
    "\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{\"type\": \"function\", \"function\": {\"name\": \"get_fact\", \"description\": \"Gets a fact relevant for the question.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"description\": {\"type\": \"string\", \"description\": \"The description of the fact to get\"}}, \"required\": [\"description\"]}}}\n",
    "</tools>\n",
    "\n",
    "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
    "<tool_call>\n",
    "{\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
    "</tool_call><|im_end|>\n",
    "<|im_start|>user\n",
    "Hey, what's the weather like in Paris right now?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77a59cb9-ec64-4550-a190-04e550f48437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a helpful question-answering assistant that bases its answers on facts from a knowledge base and always respects the prompt.\\n\\nProcess:\\n\\n    You receive an input question.\\n\\n    You get some context about the entities in the questions using description and short description.\\n\\n    You determine the reasoning path needed to answer the question based on the information available.\\n\\n    You explicitly list relevant facts, one per line, starting with \"Fact:\".\\n\\n    You explain your reasoning step by step and provide a detailed answer, justifying it based on the facts.\\n\\n    You conclude with a short and concise answer that must be grounded by the facts you found.\\n\\nYou have to answer only basing on the facts you find in the knowledge base.\\nIf you cannot find relevant facts in the knowledge base to support an answer you stop and you reply: \"I don\\'t know.\".\\nAfter generating facts, please reason on top of the facts you find and avoid generating lot of useless facts.\\n\\nYou must always follow these instructions precisely and ensure your responses adhere strictly to this prompt.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Which mountain is taller between Mont Blanc and Mount Rainier?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Reasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights and the final answer will be the taller mountain.\\nLet's try to get a bit of context about these two mountains starting with the descriptions.\\nFact: <Mont Blanc> <description> <highest mountain in the Alps> .\\nI found that Mont Blanc is the highest mountain in the Alps, but I didn't find its height.\\nFact: <Mount Rainier> <description> <stratovolcano in the U.S. state of Washington> .\\nI found that Mount Rainier is a stratovolcano and its location. But I didn't find its height.\\nFact: <Mont Blanc> <short description> <Highest mountain in the Alps (4,808 m)> .\\nI found the height of Mont Blanc.\\nFact: <Mount Rainier> <short description> <Stratovolcano in the U.S. state of Washington> .\\nI found again that Mount Rainier is a stratovolcano, but I still need to find its height.\\nFact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\\nI found Mount Rainier elevation above sea level.\\nNow that I know the height of both mountains I can give a grounded answer.\\nLong answer: Mont Blanc is 4,808 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\\n\\nAnswer: Mont Blanc.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'When was the director of Slumdog Millionaire born?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Reasoning: To answer this question, I need to find the birth date of the director of Slumdog Millionaire. Let's start with Slumdog Millionaire description.\\nFact: <Slumdog Millionaire> <description> <2008 film directed by Danny Boyle> .\\nI found that the director of Slumdog Millionaire is Danny Boyle. Now I need the birth date of Danny Boyle.\\nFact: <Danny Boyle> <date of birth> <1956-10-20T00:00:00Z>.\\nNow I have all the information I need for answering.\\nLong answer: The director of Slumdog Millionaire is Danny Boyle, who was born on October 20, 1956, so this is the answer to the question.\\n\\nAnswer: October 20, 1956.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"When did John V, Prince Of Anhalt-Zerbst's father die?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Reasoning: To answer this question, I need to find who the father of John V, Prince of Anhalt-Zerbst, was and then find the date of his death. Let's start with the description.\\nFact: <John V, Prince of Anhalt-Zerbst> <description> <Prince of Anhalt-Dessau and Anhalt-Zerbst> .\\nOk, I still need to find his father.\\nFact: <John V, Prince of Anhalt-Zerbst> <father> <Ernest I, Prince of Anhalt-Dessau> .\\nNow I know who is the father. I need to find when he died.\\nFact: <Ernest I, Prince of Anhalt-Dessau> <date of death> <1516-06-12T00:00:00Z> .\\nNow I have all the information I need to give a grounded answer.\\nLong answer: The father of John V, Prince of Anhalt-Zerbst, Ernest I, Prince of Anhalt-Dessau, died on June 12, 1516.\\n\\nAnswer: June 12, 1516.\"},\n",
       " {'role': 'user', 'content': 'Is Johnny Depp older than Brad Pitt?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth years. Let's start with the description.\\nFact: <Johnny Depp> <description> <American actor (born 1963)> .\\nI found the year of birth of Johnny Depp. I need Brad Pitt's one.\\nFact: <Brad Pitt> <description> <American actor and filmmaker> .\\nI cannot find Brad Pitt date of birth in the description.\\nFact: <Brad Pitt> <short description> <American actor (born 1963)> .\\nI found Brad Pitt's year of birth. But since it is the same as Johnny Depp's, I need more precise information about their date of birth.\\nFact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\\nI found when Johnny Depp was born, now I need Brad Pitt's date of birth.\\nFact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\\nNow I have all the information I need to give a grounded answer.\\nLong answer: Johnny Depp was born on June 9, 1963, while Brad Pitt was born on December 18, 1963. So yes, Johnny Depp is older than Brad Pitt.\\n\\nAnswer: Yes.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'During which years did Napoleon hold power in France?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Reasoning: To determine the years Napoleon held power in France, I need to identify the periods during which he held official leadership roles such as First Consul or Emperor. Maybe I can get this information from the description.\\nFact: <Napoleon Bonaparte> <description> <French military leader, French Emperor 1804–1814 and again in 1815> .\\nNow I have all the information I need to give a grounded answer.\\nLong answer: Based on the description, Napoleon Bonaparte held power in France as Emperor from 1804 to 1814, and briefly again in 1815.\\n\\nAnswer: From 1799 to 1814, and in 1815.'},\n",
       " {'role': 'user', 'content': 'Which countries share a border with Spain?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Reasoning: To answer this question, I need to find all the countries that have a land border with Spain.\\nFact: <Spain> <shares border with> <Portugal> .\\nFact: <Spain> <shares border with> <France> .\\nFact: <Spain> <shares border with> <Andorra> .\\nI found Portugal, France, and Andorra. But let me see if it there are more countries that share a border with Spain.\\nFact: <Spain> <shares border with> <Gibraltar> .\\nFact: <Spain> <shares border with> <Morocco> .\\nFact: <Spain> <diplomatic relation> <Italy> .\\nThis fact is about diplomatic relations and not borders.\\nFact: <Spain> <diplomatic relation> <Greece> .\\nAlso this fact is not about borders. I'm not able to find other countries bordering with Spain.\\nLong answer: Spain shares borders with Portugal, France, Andorra, Gibraltar, and Morocco.\\n\\nAnswer: Portugal, France, Andorra, Gibraltar, Morocco.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"In which books of A Song of Ice and Fire is Jon Snow not the Lord Commander of the Night's Watch?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Reasoning: To answer this question, I need to consider the books in the A Song of Ice and Fire series by George R.R. Martin and identify the ones where Jon Snow is not the Lord Commander of the Night's Watch. Let's start with the description.\\nFact: <A Game of Thrones> <description> <1996 novel by George R. R. Martin> .\\nThis fact doesn't give me any information about Jon Snow.\\nFact: <A Game of Thrones> <publication date> <1996-08-06T00:00:00Z> .\\nThis fact is not giving any information about Jon Snow. I think the publication date won't help me.\\nFact: <A Clash of Kings> <publication date> <1998-11-16T00:00:00Z> .\\nThese facts don't contain any information about Jon Snow. I'll try one more time.\\nFact: <A Storm of Swords> <publication date> <2000-08-08T00:00:00Z> .\\nI'm not able to find the facts about the books in which Jon Snow is not the Lord Commander, so I cannot give a grounded answer.\\nLong answer: I don't know. I was not able to find the relevant facts in the knowledge base to motivate an answer.\\n\\nAnswer: I don't know.\"}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41e7a1b2-6936-4008-8b5e-54fe89db6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_PROMPT_TEMPLATE = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': '''You are a helpful question-answering assistant that bases its answers on facts from a knowledge base and always respects the prompt.\n",
    "\n",
    "# Tools\n",
    "\n",
    "You have to call the get_fact function to answer the questions.\n",
    "\n",
    "You are provided with the function signature within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{\"type\": \"function\", \"function\": {\"name\": \"get_fact\", \"description\": \"Gets a fact relevant for the question.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"description\": {\"type\": \"string\", \"description\": \"The description of the fact to get\"}}, \"required\": [\"description\"]}}}\n",
    "</tools>\n",
    "\n",
    "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Description of the fact to get\"}}\n",
    "</tool_call>\n",
    "\n",
    "The process to answer questions:\n",
    "\n",
    "    You receive an input question.\n",
    "\n",
    "    You determine the reasoning path needed to answer the question based on the information available.\n",
    "\n",
    "    You detemine the kind of answer you are asked. It can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities (e.g. Which countries share a border with Spain?): you need to find all the answer entities and include them all in the final answer.\n",
    "\n",
    "    You get relevant facts with the \"get_fact\" function.\n",
    "\n",
    "    You can get some general context about the entities in the questions with \"get_fact\" asking for a description or a short description.\n",
    "\n",
    "    While getting facts you continue the reasoning explaining it step by step.\n",
    "\n",
    "    You conclude with a concise answer that depending on the question can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities.\n",
    "\n",
    "You have to answer only basing on the facts you find in the knowledge base.\n",
    "If you cannot find relevant facts in the knowledge base to support an answer you stop and you reply: \"I don't know.\".\n",
    "After generating facts, please reason on top of the facts you find and avoid generating lot of useless facts.\n",
    "\n",
    "You must always follow these instructions precisely and ensure your responses adhere strictly to this prompt.'''\n",
    "    },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': '''Which mountain is taller between Mont Blanc and Mount Rainier?\n",
    "'''\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': '''Reasoning: I need to provide the height of Mont Blanc and the height of Mount Rainier, then I need to compare the two heights. The final answer will be the taller mountain.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Height of Mont Blanc\"}}\n",
    "</tool_call>\n",
    "Fact: <Mont Blanc> <elevation above sea level> <4,807.02±0.5 meters> .\n",
    "Now I need the height of Mount Rainier.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Height of Mount Rainier\"}}\n",
    "</tool_call>\n",
    "Fact: <Mount Rainier> <elevation above sea level> <4,389 meters> .\n",
    "I found that Mont Blanc is 4,807 meters tall, while Mount Rainier is 4,389 meters, so Mont Blanc is taller than Mount Rainier.\n",
    "\n",
    "Answer: Mont Blanc.\n",
    "'''\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': '''When was the director of Slumdog Millionaire born?\n",
    "'''\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': '''Reasoning: To answer this question, I need to find who is the director of Slumdog Millionaire and then his birth date. The final answer will be his birth date.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Director of Slumdog Millionaire\"}}\n",
    "</tool_call>\n",
    "Fact: <Slumdog Millionaire> <director> <Danny Boyle>.\n",
    "Now I need the birth date of Danny Boyle.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\",  {\"arguments\": {\"description\": \"Birth date of Danny Boyle\"}}\n",
    "</tool_call>\n",
    "Fact: <Danny Boyle> <date of birth> <1956-10-20T00:00:00Z>.\n",
    "The director of Slumdog Millionaire is Danny Boyle, who was born on October 20, 1956, so this is the answer to the question.\n",
    "\n",
    "Answer: October 20, 1956.\n",
    "'''\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': '''Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth years. Then I need to compare them and determine who is older. The final answer will be yes if Johnny Depp is older, no elsewise.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Birth date of Johnny Depp\"}}\n",
    "</tool_call>\n",
    "Fact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
    "Now I need the birth date of Brad Pitt.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Birth date of Brad Pitt\"}}\n",
    "</tool_call>\n",
    "Fact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n",
    "Johnny Depp was born on June 9, 1963, while Brad Pitt was born on December 18, 1963. So Johnny Depp is older than Brad Pitt and the answer is yes.\n",
    "\n",
    "Answer: Yes.\n",
    "'''\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Which countries share a border with Spain?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '''Reasoning: To answer this question, I need to find all the countries that have a land border with Spain. They may be several. The answer will be the list of all these countries.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
    "</tool_call>\n",
    "Fact: <Spain> <shares border with> <Portugal> .\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
    "</tool_call>\n",
    "Fact: <Spain> <shares border with> <France> .\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
    "</tool_call>\n",
    "Fact: <Spain> <shares border with> <Andorra> .\n",
    "I found Portugal, France, and Andorra. But let me see if it there are more countries that share a border with Spain.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
    "</tool_call>\n",
    "Fact: <Spain> <shares border with> <Gibraltar> .\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
    "</tool_call>\n",
    "Fact: <Spain> <shares border with> <Morocco> .\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
    "</tool_call>\n",
    "Fact: <Spain> <diplomatic relation> <Italy> .\n",
    "This fact is about diplomatic relations and not borders.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Country bordering Spain\"}}\n",
    "</tool_call>\n",
    "Fact: <Spain> <diplomatic relation> <Greece> .\n",
    "Also this fact is not about borders. I'm not able to find other countries bordering with Spain.\n",
    "Spain shares borders with Portugal, France, Andorra, Gibraltar, and Morocco.\n",
    "\n",
    "Answer: Portugal, France, Andorra, Gibraltar, Morocco.'''\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': '''Has Hillary Clinton ever served as President of the United States?'''\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': '''Reasoning: To answer this question, I need to find out if Hillary Clinton has ever held the position of President of the United States. If yes, the answer will be yes.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Hillary Clinton president of the United States\"}}\n",
    "</tool_call>\n",
    "Fact: <Hillary Clinton> <position held> <United States Secretary of State> .\n",
    "This fact tells me that Hillary Clinton was the United States Secretary of State, but it doesn't answer the question about her presidency.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Hillary Clinton president of the United States\"}}\n",
    "</tool_call>\n",
    "Fact: <Hillary Clinton> <occupation> <Politician> .\n",
    "This facts tells she is a Politician but it is not enough.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Hillary Clinton president of the United States\"}}\n",
    "</tool_call>\n",
    "Fact: <Hillary Clinton> <occupation> <Diplomat> .\n",
    "This facts tells she is a Diplomat but not that she served as President.\n",
    "I don't have any facts that directly answer the question about Hillary Clinton's presidency, so I assume Hillary Clinton never served as President of the United States. The answer is no.\n",
    "\n",
    "Answer: No.'''\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'During which years did Napoleon hold power in France?'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': '''Reasoning: To determine the years Napoleon held power in France, I need to identify the periods during which he held power in France. Maybe I can get this information from Napoleon description. The answer will be the time frame in which Napoleon help power in France. \n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Napoleon description\"}}\n",
    "</tool_call>\n",
    "Fact: <Napoleon Bonaparte> <description> <French military leader, French Emperor 1804–1814 and again in 1815> .\n",
    "Based on the description, Napoleon Bonaparte held power in France as Emperor from 1804 to 1814, and in 1815.\n",
    "\n",
    "Answer: From 1799 to 1814, and in 1815.'''\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': '''In which books of A Song of Ice and Fire is Jon Snow not the Lord Commander of the Night's Watch?'''\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': '''Reasoning: To answer this question, I need to consider all the books in the A Song of Ice and Fire series by George R.R. Martin and identify the ones where Jon Snow is not the Lord Commander of the Night's Watch.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
    "</tool_call>\n",
    "Fact: <A Game of Thrones> <description> <1996 novel by George R. R. Martin> .\n",
    "This fact doesn't give me any information about Jon Snow.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
    "</tool_call>\n",
    "Fact: <A Game of Thrones> <publication date> <1996-08-06T00:00:00Z> .\n",
    "This fact is not giving any information about Jon Snow. I think the publication date won't help me.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
    "</tool_call>\n",
    "Fact: <A Clash of Kings> <publication date> <1998-11-16T00:00:00Z> .\n",
    "These facts don't contain any information about Jon Snow. I'll try one more time.\n",
    "<tool_call>\n",
    "{\"name\": \"get_fact\", \"arguments\": {\"description\": \"Book in which Jon Snow is not the Lord Commander of the Night's Watch\"}}\n",
    "</tool_call>\n",
    "Fact: <A Storm of Swords> <publication date> <2000-08-08T00:00:00Z> .\n",
    "I'm not able to find the facts about the books in which Jon Snow is not the Lord Commander, so I cannot give a grounded answer.\n",
    "\n",
    "Answer: I don't know.'''\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bf016-a127-4d74-b84a-ea6169788852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (devlopment rpozzi)",
   "language": "python",
   "name": "development"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
