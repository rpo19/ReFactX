{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92e44e9-b1eb-4927-805b-2f9e0c883fef",
   "metadata": {},
   "source": [
    "# Try ReFactX\n",
    "\n",
    "In order to avoid to ingest the full 800-million-facts tree, this notebook uses a small in-memory prefix tree of 31,584 facts about famous artists and directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420ca28-c083-480d-8e0a-5b5b43dc99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9eae54-9371-4296-9c95-3c91f41d6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5404188-5b5f-4952-9ad1-24d4198bfed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import time\n",
    "from transformers.generation.logits_process import LogitsProcessorList\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from datamodules.base_dataset_config import PROMPT_TEMPLATE\n",
    "from refactx import ConstrainedLogitsProcessor, ConstrainedStateList, \\\n",
    "                    PatternConstrainedState, DictIndex, patch_model\n",
    "import refactx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf9f47-0db8-4564-accc-e7b094097ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "#MODEL = 'openai/gpt-oss-20b'\n",
    "INDEX = '../indexes/simple_index.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47084e98-aed7-4be7-af30-79cf9d78205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414bf61-56ca-4ab8-9ba7-f77c74e5c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "#model = AutoModelForCausalLM.from_pretrained(MODEL, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce269dcf-f4f0-4b1e-a89b-2e72117c33fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open(INDEX) as reader:\n",
    "    refactx.populate_postgres_index(reader,\n",
    "                                    #'postgres://secondment:ofa3eebohgh6chioqu9Aep9maev6eejothith5bot4iuqu3oge7doo8uoCe0ooda@10.0.0.118:5432/postgres',\n",
    "                                    'postgres://postgres:vipez3loh4pah2ahS1aefohy5aiLoh2fooxo0ke1ahw3aiphier8gei6aith6iof@10.0.0.118:5432/postgres',\n",
    "                                    tokenizer,\n",
    "                                    'testinterpopulate',\n",
    "                                    batch_size=5000,\n",
    "                                    rootkey = -100,\n",
    "                                    configkey=-200,\n",
    "                                    switch_parameter = 7,\n",
    "                                    total_number_of_triples=None,\n",
    "                                    prefix='',\n",
    "                                    tokenizer_batch_size=5000,\n",
    "                                    add_special_tokens=False,\n",
    "                                    count_leaves=True,\n",
    "                                    debug=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878915d-e1ab-41e0-8e74-5566d33184d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = refactx.load_index(\n",
    "    'postgres://secondment:ofa3eebohgh6chioqu9Aep9maev6eejothith5bot4iuqu3oge7doo8uoCe0ooda@10.0.0.118:5432/postgres?tablename=testinterpopulate', \n",
    "    #tokenizer,\n",
    "    #configkey=-200,\n",
    "    cache='default'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10be0f2-0600-4f51-bd39-5bd62c0a56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb124606-cd51-4d48-9869-9fa93bf7f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212bdd36-79ce-4026-83a5-cb7f9d103c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is Johnny Depp older than Brad Pitt?'\n",
    "\n",
    "prompted_texts = [refactx.apply_prompt_template(PROMPT_TEMPLATE, tokenizer, question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db7b6e-5c68-46db-b3c1-019c3e5d7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prompted_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompted_texts, return_tensors='pt', padding=True, padding_side='right')\n",
    "inputs = inputs.to(model.device)\n",
    "print(inputs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d4668-a82c-4089-bee9-998051c72447",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f1993-78d5-42f8-907c-b27952d71784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for num_beams=1\n",
    "patch_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2059cd2-55a5-452d-a255-db02f4c80550",
   "metadata": {},
   "outputs": [],
   "source": [
    "refactx.CONSTRAINED_STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_beams = 1\n",
    "\n",
    "auto_streamer = streamer if num_beams == 1 else None\n",
    "\n",
    "states = [[PatternConstrainedState(\n",
    "                pattern = 'Fact:',\n",
    "                tokenizer = tokenizer,\n",
    "                cache_index = DictIndex(),\n",
    "                subtree_cache = DictIndex(),\n",
    "            )]]\n",
    "\n",
    "refactx.CONSTRAINED_STATES = ConstrainedStateList(states,\n",
    "            num_beams=num_beams,\n",
    "            num_batches = 1,\n",
    "     )\n",
    "\n",
    "constrained_processor = ConstrainedLogitsProcessor(\n",
    "    index=index,\n",
    "    states=refactx.CONSTRAINED_STATES, tokenizer=tokenizer)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    constrained_processor\n",
    "])\n",
    "\n",
    "model.eval()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=800,\n",
    "        streamer = auto_streamer,\n",
    "        do_sample = False,\n",
    "        temperature = None,\n",
    "        top_k=None,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=num_beams,\n",
    "        use_cache=True,\n",
    "        top_p=None,\n",
    "        min_p=None,\n",
    "    )\n",
    "\n",
    "print('Elapsed', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbaf124-ec00-4329-a9b3-f4e388d4fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb3f96-5716-4e69-98b7-36b176407635",
   "metadata": {},
   "source": [
    "### Visualize ReFactX output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b8386-fcbc-4bf3-b13b-e388f4bbc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "_from = len(inputs.input_ids[0]) # 0\n",
    "for i in range(out.shape[0]):\n",
    "    print('-'*30, sum(out[i][_from:]), len(out[i][_from:]))\n",
    "    print(tokenizer.decode(out[i][_from:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16882d72-e52e-42d8-9cb1-3b7e0d3f7310",
   "metadata": {},
   "source": [
    "### Generated Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7cc7c-ed8d-4b48-9e97-c12b63641329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, triple in enumerate(refactx.CONSTRAINED_STATES[0][0].generated_triples):\n",
    "    print(i, tokenizer.decode(triple), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041f8eb-c30a-4837-b752-1765878fd05a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (devlopment rpozzi)",
   "language": "python",
   "name": "development"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
