{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92e44e9-b1eb-4927-805b-2f9e0c883fef",
   "metadata": {},
   "source": [
    "# Try ReFactX\n",
    "\n",
    "In order to avoid to ingest the full 800-million-facts tree, this notebook uses a small in-memory prefix tree of 31,584 facts about famous artists and directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7420ca28-c083-480d-8e0a-5b5b43dc99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9eae54-9371-4296-9c95-3c91f41d6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5404188-5b5f-4952-9ad1-24d4198bfed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import time\n",
    "from transformers.generation.logits_process import LogitsProcessorList\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from datamodules.base_dataset_config import PROMPT_TEMPLATE\n",
    "from refactx import ConstrainedLogitsProcessor, ConstrainedStateList, \\\n",
    "                    PatternConstrainedState, DictIndex, patch_model\n",
    "import refactx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fecf9f47-0db8-4564-accc-e7b094097ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "#MODEL = 'openai/gpt-oss-20b'\n",
    "INDEX = '../indexes/simple_index.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47084e98-aed7-4be7-af30-79cf9d78205b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6414bf61-56ca-4ab8-9ba7-f77c74e5c306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.92s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1878915d-e1ab-41e0-8e74-5566d33184d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:01<00:00, 288.60it/s]\n"
     ]
    }
   ],
   "source": [
    "index = refactx.load_index(INDEX, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb124606-cd51-4d48-9869-9fa93bf7f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "212bdd36-79ce-4026-83a5-cb7f9d103c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is Johnny Depp older than Brad Pitt?'\n",
    "\n",
    "prompted_texts = [refactx.apply_prompt_template(PROMPT_TEMPLATE, tokenizer, question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03db7b6e-5c68-46db-b3c1-019c3e5d7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prompted_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 756])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompted_texts, return_tensors='pt', padding=True, padding_side='right')\n",
    "inputs = inputs.to(model.device)\n",
    "print(inputs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff6d4668-a82c-4089-bee9-998051c72447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc8f1993-78d5-42f8-907c-b27952d71784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for num_beams=1\n",
    "patch_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2059cd2-55a5-452d-a255-db02f4c80550",
   "metadata": {},
   "outputs": [],
   "source": [
    "refactx.CONSTRAINED_STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_beams = 1\n",
    "\n",
    "auto_streamer = streamer if num_beams == 1 else None\n",
    "\n",
    "states = [[PatternConstrainedState(\n",
    "                pattern = 'Fact:',\n",
    "                tokenizer = tokenizer,\n",
    "                cache_index = DictIndex(),\n",
    "                subtree_cache = DictIndex(),\n",
    "            )]]\n",
    "\n",
    "refactx.CONSTRAINED_STATES = ConstrainedStateList(states,\n",
    "            num_beams=num_beams,\n",
    "            num_batches = 1,\n",
    "     )\n",
    "\n",
    "constrained_processor = ConstrainedLogitsProcessor(\n",
    "    index=index,\n",
    "    states=refactx.CONSTRAINED_STATES, tokenizer=tokenizer)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    constrained_processor\n",
    "])\n",
    "\n",
    "model.eval()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=800,\n",
    "        streamer = auto_streamer,\n",
    "        do_sample = False,\n",
    "        temperature = None,\n",
    "        top_k=None,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=num_beams,\n",
    "        use_cache=True,\n",
    "        top_p=None,\n",
    "        min_p=None,\n",
    "    )\n",
    "\n",
    "print('Elapsed', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb3f96-5716-4e69-98b7-36b176407635",
   "metadata": {},
   "source": [
    "### Visualize ReFactX output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a1b8386-fcbc-4bf3-b13b-e388f4bbc537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ tensor(1058125, device='cuda:0') 247\n",
      "Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth dates. Once I have both dates, I can compare them to see which one is older. Let's start with finding their birth dates.\n",
      "Fact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> . \n",
      "Fact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> . \n",
      "\n",
      "I found the birth dates of both actors:\n",
      "- Johnny Depp was born on June 9, 1963.\n",
      "- Brad Pitt was born on December 18, 1963.\n",
      "\n",
      "Now let's compare their ages.\n",
      "- Johnny Depp is 60 years old.\n",
      "- Brad Pitt is 60 years old.\n",
      "\n",
      "Since they were born on different days but in the same year, we need to consider the exact day to determine who is older. However, given that the difference in age is only a few days, we can conclude that they are the same age.\n",
      "\n",
      "Answer: No.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "_from = len(inputs.input_ids[0]) # 0\n",
    "for i in range(out.shape[0]):\n",
    "    print('-'*30, sum(out[i][_from:]), len(out[i][_from:]))\n",
    "    print(tokenizer.decode(out[i][_from:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16882d72-e52e-42d8-9cb1-3b7e0d3f7310",
   "metadata": {},
   "source": [
    "### Generated Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7cc7c-ed8d-4b48-9e97-c12b63641329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, triple in enumerate(refactx.CONSTRAINED_STATES[0][0].generated_triples):\n",
    "    print(i, tokenizer.decode(triple), end='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (devlopment rpozzi)",
   "language": "python",
   "name": "development"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
