{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92e44e9-b1eb-4927-805b-2f9e0c883fef",
   "metadata": {},
   "source": [
    "# Try ReFactX\n",
    "\n",
    "In order to avoid to ingest the full 800-million-facts tree, this notebook uses a small in-memory prefix tree of 31,584 facts about famous artists and directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9eae54-9371-4296-9c95-3c91f41d6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5404188-5b5f-4952-9ad1-24d4198bfed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/development/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import time\n",
    "from transformers.generation.logits_process import LogitsProcessorList\n",
    "from transformers import TextStreamer\n",
    "from datamodules.base_dataset_config import PROMPT_TEMPLATE\n",
    "from refactx import ConstrainedLogitsProcessor, ConstrainedStateList, \\\n",
    "                    ConstrainedState, DictIndex, patch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecf9f47-0db8-4564-accc-e7b094097ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'models.qwen25_3B_model'\n",
    "INDEX = 'indexes.simple_index_qwen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1878915d-e1ab-41e0-8e74-5566d33184d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../indexes/simple_index.txt.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m index_module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINDEX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m index_config = \u001b[38;5;28mgetattr\u001b[39m(index_module, \u001b[33m'\u001b[39m\u001b[33mindex_config\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m model_module = importlib.import_module(MODEL)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/development/lib/python3.13/importlib/__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/refactx_clean/notebooks/../indexes/simple_index_qwen.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msimple_index\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexConfig\n\u001b[32m      3\u001b[39m index_config = IndexConfig(\u001b[33m'\u001b[39m\u001b[33mQwen/Qwen2.5-1.5B-Instruct\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mindex_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m index_config.clean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/notebooks/refactx_clean/notebooks/../indexes/simple_index.py:30\u001b[39m, in \u001b[36mIndexConfig.load_from_path\u001b[39m\u001b[34m(self, dataset_path, enrich)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     29\u001b[39m     actual_path = dataset_path\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mgzip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m myfile:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m.verbalized_triples = myfile.readlines()\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.verbalized_triples = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.replace(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m), \u001b[38;5;28mself\u001b[39m.verbalized_triples))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/development/lib/python3.13/gzip.py:62\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[39m\n\u001b[32m     60\u001b[39m gz_mode = mode.replace(\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os.PathLike)):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     binary_file = \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mwrite\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     64\u001b[39m     binary_file = GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/development/lib/python3.13/gzip.py:194\u001b[39m, in \u001b[36mGzipFile.__init__\u001b[39m\u001b[34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[39m\n\u001b[32m    192\u001b[39m     mode += \u001b[33m'\u001b[39m\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     fileobj = \u001b[38;5;28mself\u001b[39m.myfileobj = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    196\u001b[39m     filename = \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../indexes/simple_index.txt.gz'"
     ]
    }
   ],
   "source": [
    "index_module = importlib.import_module(INDEX)\n",
    "index_config = getattr(index_module, 'index_config')\n",
    "\n",
    "model_module = importlib.import_module(MODEL)\n",
    "model_config = getattr(model_module, 'model_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06189964-4ea7-466e-a41f-627dee8ea859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py                    bi_index_qwen.py     qwen25_index.py\n",
      "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/                   gemma3_index.py      simple_index.py\n",
      "base_http_index.py             http_index_llama.py  simple_index_llama.py\n",
      "base_postgres_index_config.py  http_index_phi4.py   simple_index_phi4.py\n",
      "bi_index.py                    http_index_qwen.py   simple_index_qwen.py\n",
      "bi_index_llama.py              llama_index.py\n",
      "bi_index_phi4.py               phi4_index.py\n"
     ]
    }
   ],
   "source": [
    "ls ../indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb124606-cd51-4d48-9869-9fa93bf7f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(model_config.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212bdd36-79ce-4026-83a5-cb7f9d103c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is Johnny Depp older than Brad Pitt?'\n",
    "\n",
    "prompted_texts = [model_config.apply_prompt_template(PROMPT_TEMPLATE, question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03db7b6e-5c68-46db-b3c1-019c3e5d7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prompted_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 756])\n"
     ]
    }
   ],
   "source": [
    "inputs = model_config.tokenizer(prompted_texts, return_tensors='pt', padding=True, padding_side='right')\n",
    "inputs = inputs.to(model_config.model.device)\n",
    "print(inputs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6d4668-a82c-4089-bee9-998051c72447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f1993-78d5-42f8-907c-b27952d71784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for num_beams=1\n",
    "patch_model(model_config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful question-answering assistant that bases its answers on facts from a knowledge base and always respects the prompt.\n",
      "\n",
      "The process to answer questions:\n",
      "\n",
      "    You receive an input question.\n",
      "\n",
      "    You determine the reasoning path needed to answer the question based on the information available.\n",
      "\n",
      "    You determine the kind of answer you are asked. It can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities (e.g. Which countries share a border with Spain?): you need to find all the answer entities and include them all in the final answer.\n",
      "\n",
      "    You get relevant facts with the \"Fact:\" command. You can rely on these facts and use them a proof for your answer.\n",
      "    While getting facts you continue the reasoning explaining it step by step.\n",
      "\n",
      "    Often description or short description may be useful for answering questions.\n",
      "\n",
      "    You conclude with a concise answer that depending on the question can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities.\n",
      "\n",
      "    The answer MUST be based on the proofs you found with \"Fact:\".\n",
      "\n",
      "If you didn't find proofs with \"Fact:\" that support an answer you stop and you reply: \"I don't know.\".\n",
      "\n",
      "If the question requires to find proof that an event happen and you didn't find any proof, you can assume that event didn't happen.\n",
      "\n",
      "In case you are taking too long for answering (e.g., you already generated ten facts that are not useful for the question), you stop and you answer based on the proofs you acquired to that point.\n",
      "\n",
      "You must always follow these instructions precisely and ensure your responses adhere strictly to this prompt.<|im_end|>\n",
      "<|im_start|>user\n",
      "When was the director of Slumdog Millionaire born?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To answer this question, I need to find who is the director of Slumdog Millionaire and then his birth date. The final answer will be his birth date.\n",
      "Let's start with Slumdog Millionaire description.\n",
      "Fact: <Slumdog Millionaire> <description> <2008 film directed by Danny Boyle> .\n",
      "I found that the director of Slumdog Millionaire is Danny Boyle. Now I need the birth date of Danny Boyle.\n",
      "Fact: <Danny Boyle> <date of birth> <1956-10-20T00:00:00Z> .\n",
      "I found proof that the director of Slumdog Millionaire is Danny Boyle, who was born on October 20, 1956, so this is the answer to the question.\n",
      "\n",
      "Answer: October 20, 1956.<|im_end|>\n",
      "<|im_start|>user\n",
      "During which years did Napoleon hold power in France?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To determine the years Napoleon held power in France, I need to identify the periods during which he held power in France. Maybe I can get this information from Napoleon description. The answer will be the time frame in which Napoleon help power in France.\n",
      "Let's start with the description.\n",
      "Fact: <Napoleon Bonaparte> <description> <French military leader, French Emperor 1804â€“1814 and again in 1815> .\n",
      "I found proof that Napoleon Bonaparte held power in France as Emperor from 1804 to 1814, and briefly again in 1815.\n",
      "\n",
      "Answer: From 1799 to 1814, and in 1815.<|im_end|>\n",
      "<|im_start|>user\n",
      "Is Johnny Depp older than Brad Pitt?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth dates. Once I have both dates, I can compare them to see which one is older. Let's start with finding their birth dates.\n",
      "Fact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
      "Fact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n",
      "I found proof that Johnny Depp was born on June 9, 1963, and Brad Pitt was born on December 18, 1963. Now I need to compare these dates to determine who is older.\n",
      "\n",
      "Answer: Johnny Depp is not older than Brad Pitt.<|im_end|>\n",
      "Elapsed 12.317781925201416\n"
     ]
    }
   ],
   "source": [
    "num_beams = 1\n",
    "\n",
    "auto_streamer = streamer if num_beams == 1 else None\n",
    "\n",
    "states = ConstrainedStateList(\n",
    "    [ConstrainedState(\n",
    "                begin_pattern = model_config.switch_pattern,\n",
    "                end_pattern = model_config.newline_token,\n",
    "                cache_index = DictIndex(end_of_triple=index_config.index.end_of_triple),\n",
    "                subtree_cache = DictIndex(end_of_triple=index_config.index.end_of_triple),\n",
    "                oneleaf_cache = DictIndex(end_of_triple=index_config.index.end_of_triple)\n",
    "            ) for _ in range(num_beams)],\n",
    "            num_beams=num_beams,\n",
    "            batch_size = 1,\n",
    "            pad_token_id = model_config.tokenizer.eos_token_id)\n",
    "\n",
    "constrained_processor = ConstrainedLogitsProcessor(\n",
    "    index=index_config.index,\n",
    "    end_token=model_config.newline_token, states=states, tokenizer=model_config.tokenizer)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    constrained_processor\n",
    "])\n",
    "\n",
    "model_config.model.eval()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model_config.model.generate(\n",
    "        **inputs,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=800,\n",
    "        streamer = auto_streamer,\n",
    "        do_sample = False,\n",
    "        temperature = None,\n",
    "        top_k=None,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=num_beams,\n",
    "        use_cache=True,\n",
    "        top_p=None,\n",
    "        min_p=None,\n",
    "        kwargs = {'constrained_state': states}, # passing state\n",
    "    )\n",
    "\n",
    "print('Elapsed', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb3f96-5716-4e69-98b7-36b176407635",
   "metadata": {},
   "source": [
    "### Visualize ReFactX output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1b8386-fcbc-4bf3-b13b-e388f4bbc537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ tensor(902001, device='cuda:1') 184\n",
      "Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth dates. Once I have both dates, I can compare them to see which one is older. Let's start with finding their birth dates.\n",
      "Fact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
      "Fact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n",
      "I found proof that Johnny Depp was born on June 9, 1963, and Brad Pitt was born on December 18, 1963. Now I need to compare these dates to determine who is older.\n",
      "\n",
      "Answer: Johnny Depp is not older than Brad Pitt.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "_from = len(inputs.input_ids[0]) # 0\n",
    "for i in range(out.shape[0]):\n",
    "    print('-'*30, sum(out[i][_from:]), len(out[i][_from:]))\n",
    "    print(model_config.tokenizer.decode(out[i][_from:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16882d72-e52e-42d8-9cb1-3b7e0d3f7310",
   "metadata": {},
   "source": [
    "### Generated Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb7cc7c-ed8d-4b48-9e97-c12b63641329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
      "1  <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n"
     ]
    }
   ],
   "source": [
    "for i, triple in enumerate(states[0].generated_triples):\n",
    "    print(i, model_config.tokenizer.decode(triple)[:-1], end='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (devlopment rpozzi)",
   "language": "python",
   "name": "development"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
