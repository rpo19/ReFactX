{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92e44e9-b1eb-4927-805b-2f9e0c883fef",
   "metadata": {},
   "source": [
    "# Try ReFactX\n",
    "\n",
    "In order to avoid to ingest the full 800-million-facts tree, this notebook uses a small in-memory prefix tree of 31,584 facts about famous artists and directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5404188-5b5f-4952-9ad1-24d4198bfed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import time\n",
    "from transformers.generation.logits_process import LogitsProcessorList\n",
    "from transformers import TextStreamer\n",
    "from base_dataset_config import PROMPT_TEMPLATE\n",
    "from ctrie import ConstrainedLogitsProcessor, ConstrainedStateList, \\\n",
    "                    ConstrainedState, DictIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecf9f47-0db8-4564-accc-e7b094097ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'qwen25_3B_model'\n",
    "INDEX = 'simple_index_qwen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1878915d-e1ab-41e0-8e74-5566d33184d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:01<00:00, 246.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen2.5-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65034a7101604eb2b7af04297b3a0a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_module = importlib.import_module(INDEX)\n",
    "index_config = getattr(index_module, 'index_config')\n",
    "\n",
    "model_module = importlib.import_module(MODEL)\n",
    "model_config = getattr(model_module, 'model_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb124606-cd51-4d48-9869-9fa93bf7f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(model_config.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212bdd36-79ce-4026-83a5-cb7f9d103c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Is Johnny Depp older than Brad Pitt?'\n",
    "\n",
    "prompted_texts = [model_config.apply_prompt_template(PROMPT_TEMPLATE, question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03db7b6e-5c68-46db-b3c1-019c3e5d7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prompted_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec76aa9a-2a48-4f76-8856-3631a57d2ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 756])\n"
     ]
    }
   ],
   "source": [
    "inputs = model_config.tokenizer(prompted_texts, return_tensors='pt', padding=True, padding_side='right')\n",
    "inputs = inputs.to(model_config.model.device)\n",
    "print(inputs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6d4668-a82c-4089-bee9-998051c72447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf11ff9-ffbe-4a97-8acc-ca52931d7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful question-answering assistant that bases its answers on facts from a knowledge base and always respects the prompt.\n",
      "\n",
      "The process to answer questions:\n",
      "\n",
      "    You receive an input question.\n",
      "\n",
      "    You determine the reasoning path needed to answer the question based on the information available.\n",
      "\n",
      "    You determine the kind of answer you are asked. It can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities (e.g. Which countries share a border with Spain?): you need to find all the answer entities and include them all in the final answer.\n",
      "\n",
      "    You get relevant facts with the \"Fact:\" command. You can rely on these facts and use them a proof for your answer.\n",
      "    While getting facts you continue the reasoning explaining it step by step.\n",
      "\n",
      "    Often description or short description may be useful for answering questions.\n",
      "\n",
      "    You conclude with a concise answer that depending on the question can be a yes/no, a single entity, or a list of entities. Pay attention to the questions whose answer is a list of entities.\n",
      "\n",
      "    The answer MUST be based on the proofs you found with \"Fact:\".\n",
      "\n",
      "If you didn't find proofs with \"Fact:\" that support an answer you stop and you reply: \"I don't know.\".\n",
      "\n",
      "If the question requires to find proof that an event happen and you didn't find any proof, you can assume that event didn't happen.\n",
      "\n",
      "In case you are taking too long for answering (e.g., you already generated ten facts that are not useful for the question), you stop and you answer based on the proofs you acquired to that point.\n",
      "\n",
      "You must always follow these instructions precisely and ensure your responses adhere strictly to this prompt.<|im_end|>\n",
      "<|im_start|>user\n",
      "When was the director of Slumdog Millionaire born?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To answer this question, I need to find who is the director of Slumdog Millionaire and then his birth date. The final answer will be his birth date.\n",
      "Let's start with Slumdog Millionaire description.\n",
      "Fact: <Slumdog Millionaire> <description> <2008 film directed by Danny Boyle> .\n",
      "I found that the director of Slumdog Millionaire is Danny Boyle. Now I need the birth date of Danny Boyle.\n",
      "Fact: <Danny Boyle> <date of birth> <1956-10-20T00:00:00Z> .\n",
      "I found proof that the director of Slumdog Millionaire is Danny Boyle, who was born on October 20, 1956, so this is the answer to the question.\n",
      "\n",
      "Answer: October 20, 1956.<|im_end|>\n",
      "<|im_start|>user\n",
      "During which years did Napoleon hold power in France?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To determine the years Napoleon held power in France, I need to identify the periods during which he held power in France. Maybe I can get this information from Napoleon description. The answer will be the time frame in which Napoleon help power in France.\n",
      "Let's start with the description.\n",
      "Fact: <Napoleon Bonaparte> <description> <French military leader, French Emperor 1804–1814 and again in 1815> .\n",
      "I found proof that Napoleon Bonaparte held power in France as Emperor from 1804 to 1814, and briefly again in 1815.\n",
      "\n",
      "Answer: From 1799 to 1814, and in 1815.<|im_end|>\n",
      "<|im_start|>user\n",
      "Is Johnny Depp older than Brad Pitt?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth dates. Once I have both dates, I can compare them to see which one is older. Let's start with finding their birth dates.\n",
      "Fact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
      "Fact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n",
      "I found proof that Johnny Depp was born on June 9, 1963, and Brad Pitt was born on December 18, 1963. Now I need to compare these dates to determine who is older.\n",
      "\n",
      "Answer: Johnny Depp is not older than Brad Pitt.<|im_end|>\n",
      "Elapsed 12.317781925201416\n"
     ]
    }
   ],
   "source": [
    "num_beams = 1\n",
    "\n",
    "auto_streamer = streamer if num_beams == 1 else None\n",
    "\n",
    "states = ConstrainedStateList(\n",
    "    [ConstrainedState(\n",
    "                begin_pattern = model_config.switch_pattern,\n",
    "                end_pattern = model_config.newline_token,\n",
    "                cache_index = DictIndex(end_of_triple=index_config.index.end_of_triple),\n",
    "                subtree_cache = DictIndex(end_of_triple=index_config.index.end_of_triple),\n",
    "                oneleaf_cache = DictIndex(end_of_triple=index_config.index.end_of_triple)\n",
    "            ) for _ in range(num_beams)],\n",
    "            num_beams=num_beams,\n",
    "            batch_size = 1,\n",
    "            pad_token_id = model_config.tokenizer.eos_token_id)\n",
    "\n",
    "constrained_processor = ConstrainedLogitsProcessor(\n",
    "    index=index_config.index,\n",
    "    end_token=model_config.newline_token, states=states, tokenizer=model_config.tokenizer)\n",
    "logits_processor_list = LogitsProcessorList([\n",
    "    constrained_processor\n",
    "])\n",
    "\n",
    "model_config.model.eval()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model_config.model.generate(\n",
    "        **inputs,\n",
    "        logits_processor=logits_processor_list,\n",
    "        max_new_tokens=800,\n",
    "        streamer = auto_streamer,\n",
    "        do_sample = False,\n",
    "        temperature = None,\n",
    "        top_k=None,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=num_beams,\n",
    "        use_cache=True,\n",
    "        top_p=None,\n",
    "        min_p=None,\n",
    "        kwargs = {'constrained_state': states}, # passing state\n",
    "    )\n",
    "\n",
    "print('Elapsed', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb3f96-5716-4e69-98b7-36b176407635",
   "metadata": {},
   "source": [
    "### Visualize ReFactX output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1b8386-fcbc-4bf3-b13b-e388f4bbc537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ tensor(902001, device='cuda:1') 184\n",
      "Reasoning: To determine if Johnny Depp is older than Brad Pitt, I need to find their respective birth dates. Once I have both dates, I can compare them to see which one is older. Let's start with finding their birth dates.\n",
      "Fact: <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
      "Fact: <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n",
      "I found proof that Johnny Depp was born on June 9, 1963, and Brad Pitt was born on December 18, 1963. Now I need to compare these dates to determine who is older.\n",
      "\n",
      "Answer: Johnny Depp is not older than Brad Pitt.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "_from = len(inputs.input_ids[0]) # 0\n",
    "for i in range(out.shape[0]):\n",
    "    print('-'*30, sum(out[i][_from:]), len(out[i][_from:]))\n",
    "    print(model_config.tokenizer.decode(out[i][_from:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16882d72-e52e-42d8-9cb1-3b7e0d3f7310",
   "metadata": {},
   "source": [
    "### Generated Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb7cc7c-ed8d-4b48-9e97-c12b63641329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  <Johnny Depp> <date of birth> <1963-06-09T00:00:00Z> .\n",
      "1  <Brad Pitt> <date of birth> <1963-12-18T00:00:00Z> .\n"
     ]
    }
   ],
   "source": [
    "for i, triple in enumerate(states[0].generated_triples):\n",
    "    print(i, model_config.tokenizer.decode(triple)[:-1], end='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda base)",
   "language": "python",
   "name": "condabase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
