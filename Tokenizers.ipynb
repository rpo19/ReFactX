{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f6e5a3-a292-445f-bcd4-20d9ce9ee1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f273bf27-a416-49cc-8a7d-8657f3905565",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_llama_1B = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "tokenizer_qwen_1B = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "# microsoft phi\n",
    "# phi3 has different tokenizer # we use other families for small models\n",
    "tokenizer_phi4_14B = AutoTokenizer.from_pretrained(\"microsoft/phi-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d4aa0ac-e4c7-4d84-97a8-c773244bd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other tokenizers\n",
    "\n",
    "# meta llama\n",
    "tokenizer_llama_3B = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "tokenizer_llama_8B = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "tokenizer_llama_70B = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.3-70B-Instruct\")\n",
    "\n",
    "# alibaba qwen\n",
    "tokenizer_qwen_3B = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")\n",
    "tokenizer_qwen_7B = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "tokenizer_qwen_14B = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-14B-Instruct\")\n",
    "tokenizer_qwen_32B = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-32B-Instruct\")\n",
    "tokenizer_qwen_72B = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-72B-Instruct\")\n",
    "\n",
    "# google gemma\n",
    "tokenizer_gemma_1B = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "tokenizer_gemma_4B = AutoTokenizer.from_pretrained(\"google/gemma-3-4b-it\")\n",
    "tokenizer_gemma_12B = AutoTokenizer.from_pretrained(\"google/gemma-3-12b-it\")\n",
    "tokenizer_gemma_27B = AutoTokenizer.from_pretrained(\"google/gemma-3-27b-it\")\n",
    "\n",
    "# mistral\n",
    "tokenizer_mistral_24B = AutoTokenizer.from_pretrained(\"mistralai/Mistral-Small-24B-Instruct-2501\")\n",
    "\n",
    "# deepseek\n",
    "tokenizer_deepseek_qwen_1B = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "tokenizer_deepseek_qwen_7B = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\")\n",
    "tokenizer_deepseek_qwen_14B = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\")\n",
    "tokenizer_deepseek_llama_8B = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\")\n",
    "\n",
    "# alibaba qwen qwq\n",
    "tokenizer_qwq_32B = AutoTokenizer.from_pretrained(\"Qwen/QwQ-32B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ef05d8-bd29-4c33-b303-acd5b871006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenizer_gemma_1B.vocab == tokenizer_gemma_1B.vocab\n",
    "assert tokenizer_gemma_4B.vocab == tokenizer_gemma_1B.vocab\n",
    "assert tokenizer_gemma_12B.vocab == tokenizer_gemma_1B.vocab\n",
    "assert tokenizer_gemma_27B.vocab == tokenizer_gemma_1B.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a46b00-c7d2-464a-afb2-7d6de0b7c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenizer_qwen_1B.vocab == tokenizer_qwen_1B.vocab\n",
    "assert tokenizer_qwen_7B.vocab == tokenizer_qwen_1B.vocab\n",
    "assert tokenizer_qwen_14B.vocab == tokenizer_qwen_1B.vocab\n",
    "assert tokenizer_qwen_32B.vocab == tokenizer_qwen_1B.vocab\n",
    "assert tokenizer_qwen_72B.vocab == tokenizer_qwen_1B.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f7f4a1-33af-4932-a731-e5c77319d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenizer_llama_1B.vocab == tokenizer_llama_1B.vocab\n",
    "assert tokenizer_llama_3B.vocab == tokenizer_llama_1B.vocab\n",
    "assert tokenizer_llama_8B.vocab == tokenizer_llama_1B.vocab\n",
    "assert tokenizer_llama_70B.vocab == tokenizer_llama_1B.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a29a811-bb0b-4f37-972e-3bb6c4d0a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenizer_deepseek_qwen_7B.vocab == tokenizer_deepseek_qwen_1B.vocab \n",
    "assert tokenizer_deepseek_qwen_14B.vocab == tokenizer_deepseek_qwen_1B.vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f9c754-df65-42db-a972-a4b147abbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwen != llama\n",
    "assert tokenizer_qwen_1B.vocab != tokenizer_llama_1B.vocab\n",
    "# phi != llama\n",
    "assert tokenizer_phi4_14B.vocab != tokenizer_llama_1B.vocab\n",
    "# gemma != llama\n",
    "assert tokenizer_gemma_1B.vocab != tokenizer_llama_1B.vocab\n",
    "# mistral != llama\n",
    "assert tokenizer_mistral_24B.vocab != tokenizer_llama_1B.vocab\n",
    "# qwen != deepseek qwen\n",
    "assert tokenizer_qwen_1B.vocab != tokenizer_deepseek_qwen_1B.vocab\n",
    "# llama != deepseek llama\n",
    "assert tokenizer_llama_1B.vocab != tokenizer_deepseek_llama_8B.vocab\n",
    "# deepseek qwen != deepseek llama\n",
    "assert tokenizer_deepseek_qwen_1B.vocab != tokenizer_deepseek_llama_8B.vocab\n",
    "# qwen != qwq\n",
    "assert tokenizer_qwen_1B.vocab != tokenizer_qwq_32B.vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0981773f-918f-476d-9673-5e15af073c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[574, 374, 264, 1273, 11652]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_qwen_3B.encode('this is a test sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcca6b5e-aa55-4fa1-ad02-863b95d8e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 576, 374, 264, 1296, 11914]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_llama_1B.encode('this is a test sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c255fc65-7461-46f3-888b-00306c260551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9312, 29, 366, 65, 29, 366, 66, 29, 659]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_qwen_1B.encode('<a> <b> <c> .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d832f3c6-dcdd-4cc9-9c99-15f4d4b023bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_qwen_1B.convert_ids_to_tokens(200000) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a6a0b6c-e83f-4474-be3e-d505a5a97811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100352"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer_phi4_14B.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478862b7-4820-4e34-b129-ec909d56e1b5",
   "metadata": {},
   "source": [
    "# Find tokenizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbe800ed-0fb3-423d-b364-d534d30959b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_phi4_14B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "587f20d9-2521-4ead-bbf4-2ad39c9e73c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100352, 100351)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab), max(tokenizer.vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dabf15f-8b8b-402b-9746-e25efbce10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "Ċ\n"
     ]
    }
   ],
   "source": [
    "newline_token_id = tokenizer.encode('''\n",
    "''')[-1]\n",
    "print(newline_token_id)\n",
    "newline_token = tokenizer.convert_ids_to_tokens(newline_token_id)\n",
    "print(newline_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d88253d3-195b-4418-ace3-66c81fc9a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_pattern_str = '<fact>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8470b4af-5039-4eb5-a23f-7cf66952014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 34210, 29] ['<', 'fact', '>']\n",
      "[366, 34210, 29] ['Ġ<', 'fact', '>']\n",
      "{27: {34210: {29: {}}}, 366: {34210: {29: {}}}}\n"
     ]
    }
   ],
   "source": [
    "switch_pattern = {}\n",
    "no_space = tokenizer.encode(switch_pattern_str, add_special_tokens=False)\n",
    "print(no_space, list(map(tokenizer.convert_ids_to_tokens, no_space)))\n",
    "space = tokenizer.encode(' '+switch_pattern_str, add_special_tokens=False)\n",
    "print(space, list(map(tokenizer.convert_ids_to_tokens, space)))\n",
    "\n",
    "lv = switch_pattern\n",
    "for tok in no_space:\n",
    "    lv[tok] = {}\n",
    "    lv = lv[tok]\n",
    "\n",
    "lv = switch_pattern\n",
    "for tok in space:\n",
    "    lv[tok] = {}\n",
    "    lv = lv[tok]\n",
    "print(switch_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d097da7-74e0-417f-9c81-4b44b63c52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16533, 25]\n"
     ]
    }
   ],
   "source": [
    "switch_pattern = tokenizer.encode('''\n",
    "Answer:''')[1:]\n",
    "print(switch_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3469d75b-19be-4c85-9d2c-a60213dbde7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n"
     ]
    }
   ],
   "source": [
    "end_of_triple = tokenizer.encode('''triple .''')[-1]\n",
    "print(end_of_triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e9bec2-6281-497e-9949-7df3082809fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151645"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "387eb424-33c9-4c1a-ba01-a1898415ddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '<|im_end|>',\n",
       " 'pad_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['<|im_start|>',\n",
       "  '<|im_end|>',\n",
       "  '<|object_ref_start|>',\n",
       "  '<|object_ref_end|>',\n",
       "  '<|box_start|>',\n",
       "  '<|box_end|>',\n",
       "  '<|quad_start|>',\n",
       "  '<|quad_end|>',\n",
       "  '<|vision_start|>',\n",
       "  '<|vision_end|>',\n",
       "  '<|vision_pad|>',\n",
       "  '<|image_pad|>',\n",
       "  '<|video_pad|>']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e9297df-b07e-46f0-8181-bc13ea502622",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd5e4730-f606-4614-b2f9-7162ad4c2e43",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Qwen2TokenizerFast has no attribute add_bos_token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_bos_token\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1108\u001b[0m, in \u001b[0;36mSpecialTokensMixin.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(attr_as_tokens) \u001b[38;5;28;01mif\u001b[39;00m attr_as_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m-> 1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Qwen2TokenizerFast has no attribute add_bos_token"
     ]
    }
   ],
   "source": [
    "tokenizer.add_bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a53fc7d-b97a-4135-9648-6da04ee75552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao come stai?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(['ciao come stai?'], add_special_tokens=False)['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9776395-cc32-48e8-bab5-8cbf990ec111",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90980006-aefd-4b64-8bc8-8bdf44d6dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_and_eq(vocab1, vocab2):\n",
    "    sort_fun = lambda x: x[1]\n",
    "    vocab1_ordered = [(k,v) for k,v in vocab1.items()]\n",
    "    vocab1_ordered.sort(key=sort_fun)\n",
    "    vocab2_ordered = [(k,v) for k,v in vocab2.items()]\n",
    "    vocab2_ordered.sort(key=sort_fun)\n",
    "\n",
    "    diff_len = len(vocab1) - len(vocab2)\n",
    "\n",
    "    i = 0\n",
    "    end = min((len(vocab1), len(vocab2)))\n",
    "    while True:\n",
    "        if i == end:\n",
    "            break\n",
    "        if vocab1_ordered[i] != vocab2_ordered[i]:\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    eq_up_to = i       \n",
    "\n",
    "    eq = vocab1_ordered == vocab2_ordered\n",
    "    diff12 = set(vocab1.keys()) - set(vocab2.keys())\n",
    "    diff21 = set(vocab2.keys()) - set(vocab1.keys())\n",
    "    return eq, diff_len, eq_up_to, diff12, diff21, vocab1_ordered, vocab2_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22a003eb-3ed3-465e-96c4-660ea3a617e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq, diff_len, eq_up_to, diff12, diff21, tk1, tk2 = order_and_eq(tokenizer_phi4_14B.vocab, tokenizer_qwen_1B.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2a5b017-af4c-4ac4-8c61-d95a7a581352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, -51313, 410, 1190, 52503)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq, diff_len, eq_up_to, len(diff12), len(diff21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4afb6607-cb72-45f5-a31c-ed7b24ea1d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_up_to == len(tokenizer_qwen_1B.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88a4cf3b-713d-4fea-be9b-3db877817ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!', 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqwen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f06b2749-a019-4cc9-a2a7-eac9456aee6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</think>', '</tool_response>', '<think>', '<tool_response>'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d804649a-ada7-4ed0-a297-346a6309cb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3672d870-a3da-445b-88d0-687541bf8103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<|vision_pad|>', 151654),\n",
       " ('<|image_pad|>', 151655),\n",
       " ('<|video_pad|>', 151656),\n",
       " ('<tool_call>', 151657),\n",
       " ('</tool_call>', 151658),\n",
       " ('<|fim_prefix|>', 151659),\n",
       " ('<|fim_middle|>', 151660),\n",
       " ('<|fim_suffix|>', 151661),\n",
       " ('<|fim_pad|>', 151662),\n",
       " ('<|repo_name|>', 151663),\n",
       " ('<|file_sep|>', 151664),\n",
       " ('<tool_response>', 151665),\n",
       " ('</tool_response>', 151666),\n",
       " ('<think>', 151667),\n",
       " ('</think>', 151668)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqwq[-15:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda base)",
   "language": "python",
   "name": "condabase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
